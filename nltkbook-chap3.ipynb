{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 3: Processing Raw Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c2eb58aa5243b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from urllib import request"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:46.421354Z",
     "start_time": "2024-04-20T12:18:46.416271Z"
    }
   },
   "id": "2e1af2ea9c073a19",
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 1176812 ï»¿The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\r\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.gutenberg.org/files/2554/2554-0.txt'\n",
    "response = request.urlopen(url) \n",
    "raw = response.read().decode('utf-8')\n",
    "print(type(raw), len(raw), raw[:75])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:48.838146Z",
     "start_time": "2024-04-20T12:18:46.737673Z"
    }
   },
   "id": "417a11f454819a90",
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 257058 ['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "print(type(tokens), len(tokens), tokens[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:49.544580Z",
     "start_time": "2024-04-20T12:18:48.842155Z"
    }
   },
   "id": "e33f436b06458252",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insight', 'impresses', 'us', 'as', 'wisdom', '...', 'that', 'wisdom', 'of', 'the', 'heart', 'which', 'we', 'seek', 'that', 'we', 'may', 'learn', 'from', 'it', 'how', 'to', 'live', '.', 'All', 'his', 'other', 'gifts', 'came', 'to', 'him', 'from', 'nature', ',', 'this', 'he', 'won', 'for']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Project Gutenberg; Ilya\n",
      "Petrovitch; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(text[1024:1062])\n",
    "print(text.collocations())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:49.804955Z",
     "start_time": "2024-04-20T12:18:49.545308Z"
    }
   },
   "id": "60f3508389663891",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 37306\n",
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\n"
     ]
    }
   ],
   "source": [
    "url1 = 'http://news.bbc.co.uk/2/hi/health/2284783.stm'\n",
    "html = request.urlopen(url1).read().decode('utf8')\n",
    "print(type(html), len(html))\n",
    "print(html[:60])\n",
    "#print(html)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:49.971397Z",
     "start_time": "2024-04-20T12:18:49.806231Z"
    }
   },
   "id": "4cb667ae56daf57f",
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "24338\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "raw1 = BeautifulSoup(html, 'html.parser').get_text() \n",
    "tokens_html = word_tokenize(raw1)\n",
    "text_html = nltk.Text(tokens_html)\n",
    "text_html.concordance('gene')\n",
    "#print(tokens_html)\n",
    "\n",
    "print(html.find('of the'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.001701Z",
     "start_time": "2024-04-20T12:18:49.972270Z"
    }
   },
   "id": "8583cd034c0699ad",
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hp_1 = open('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')\n",
    "raw_HP = hp_1.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.005543Z",
     "start_time": "2024-04-20T12:18:50.002555Z"
    }
   },
   "id": "e47be2abe3215826",
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.008347Z",
     "start_time": "2024-04-20T12:18:50.006194Z"
    }
   },
   "id": "9f94c64b7773b66",
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's\n",
      "the\n",
      "worst\n",
      "case\n",
      "scenario\n",
      "lullaby\n",
      "I t ' s   t h e   w o r s t   c a s e   s c e n a r i o   l u l l a b y "
     ]
    }
   ],
   "source": [
    "my_sentence = 'It\\'s the worst case scenario lullaby'\n",
    "for i in my_sentence.split(' '):\n",
    "    print(i)\n",
    "    \n",
    "for char in my_sentence: \n",
    "    print(char, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.011812Z",
     "start_time": "2024-04-20T12:18:50.009605Z"
    }
   },
   "id": "7b8288161b316ba1",
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aba', 'abac', 'abaca', 'abaff', 'abb', 'abed', 'acca', 'accede', 'ace', 'ad', 'adad', 'add', 'adda', 'added', 'ade', 'adead', 'ae', 'aface', 'affa', 'ajaja', 'b', 'ba', 'baa', 'baba', 'babe', 'bac', 'bacaba', 'bacca', 'baccae', 'bad', 'bade', 'bae', 'baff', 'bajada', 'be', 'bead', 'beaded', 'bebed', 'bed', 'bedad', 'bedded', 'bedead', 'bedeaf', 'bee', 'beef', 'bejade', 'c', 'ca', 'cab', 'caba', 'cabda', 'cad', 'cade', 'caeca', 'caffa', 'ce', 'cede', 'cee', 'd', 'da', 'dab', 'dabb', 'dabba', 'dace', 'dad', 'dada', 'dade', 'dae', 'daff', 'de', 'dead', 'deaf', 'deb', 'decad', 'decade', 'dee', 'deed', 'deedeed', 'deface', 'e', 'ea', 'ebb', 'ecad', 'edea', 'efface', 'f', 'fa', 'facade', 'face', 'faced', 'fad', 'fade', 'faded', 'fae', 'faff', 'fe', 'fed', 'fee', 'feed', 'j', 'jab', 'jabbed', 'jade', 'jaded', 'jed', 'jeff']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'j', 'k', 'l', 'm', 'n', 'o']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']\n"
     ]
    }
   ],
   "source": [
    "word_list = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "# print([w for w in word_list if re.search('ed$', w)])\n",
    "# print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "# print([w for w in word_list if re.search('..j..t..', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]+$', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj]+$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-o]$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.286157Z",
     "start_time": "2024-04-20T12:18:50.012856Z"
    }
   },
   "id": "9403ab0726ddab0a",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "print([w for w in word_list if re.search(r'^..j..t..$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.418069Z",
     "start_time": "2024-04-20T12:18:50.288453Z"
    }
   },
   "id": "6003f991e5d91e7d",
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\\n\n",
      "\n",
      "\\b\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/26318287/what-does-r-mean-before-a-regex-pattern\n",
    "print('\\n') # Prints a newline character\n",
    "print(r'\\n') # Escape sequence is not processed\n",
    "print('\\b') # Prints a backspace character\n",
    "print(r'\\b') # Escape sequence is not processed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.420929Z",
     "start_time": "2024-04-20T12:18:50.418914Z"
    }
   },
   "id": "63eb5733d21fbc30",
   "execution_count": 143
  },
  {
   "cell_type": "markdown",
   "source": [
    "I guess I got it. So by prefixing with 'r' we kinda say to Python not to read into that but simply to pass a combination to re library, ok!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6b535d84843aa1b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009, 12, 31]\n"
     ]
    }
   ],
   "source": [
    "print([int(n) for n in re.findall(r'[0-9]{2,}', '2009-12-31')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.425699Z",
     "start_time": "2024-04-20T12:18:50.421629Z"
    }
   },
   "id": "f902aa2546d6c412",
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P}lease could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{F}rom all the unborn chicken\n",
      "{V}oices in my head\n"
     ]
    }
   ],
   "source": [
    "paranoid = \"\"\"Please could you stop the noise?\n",
    "I'm tryna get some rest\n",
    "From all the unborn chicken\n",
    "Voices in my head\"\"\"\n",
    "pattern = r'^[A-Z]'\n",
    "pattern1 = r'\\?$'\n",
    "pattern2 = r'es$' # finds nothing because it thinks of the line as the whole string and no line ends with 'es', so in order it to work I have to tokenize it first \n",
    "\n",
    "nltk.re_show(pattern, paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.428412Z",
     "start_time": "2024-04-20T12:18:50.426433Z"
    }
   },
   "id": "98a5c5477f6af1e",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n",
      "as accurately as possible; as well as the; as faithfully as possible;\n",
      "as much as what; as neat as a; as simple as you; as well as other; as\n",
      "well as other; as involved as determining; as well as other; as\n",
      "important as another; as accurately as possible; as accurate as any;\n",
      "as much as any; as different as a; as Orphic as that; as coppery as\n",
      "Delawares; as good as another; as large as small; as well as ease; as\n",
      "well as their; as well as possible; as straight as possible; as well\n",
      "as nailed; as smoothly as the; as soon as a; as well as injuries; as\n",
      "well as many; as well as reason; as well as in; as well as of; as well\n",
      "as a; as well as summer; as well as providing; as important as\n",
      "cooling; as evenly as it; as much as shading; as well as some; as well\n",
      "as subsoil; as high as possible; as well as many; as general as\n",
      "electrical; as long as the; as well as the; as much as was; as well as\n",
      "set; as well as by; as high as 15; as well as aid; as much as\n",
      "possible; as well as personalities; as low as a; as well as the; as\n",
      "much as glass; as popular as renting; as expensive as most; as well as\n",
      "relative; as well as by; as well as the; as far as possible; as far as\n",
      "radiation; as well as theoretical; as well as nuclear; as small as\n",
      "possible; as well as soap; as effective as the; as much as\n",
      "approximately; as well as information; as little as one; as much as\n",
      "an; as low as Af; as long as the; as far as possible; as well as\n",
      "their; as well as Hand; as well as all; as well as fractionation; as\n",
      "potent as the; as well as fever; as large as 3; as well as varying; as\n",
      "well as the; as long as 2; as far as emotional; as well as the; as\n",
      "well as regarding; as well as enthusiasm; as well as by; as well as\n",
      "her; as well as a; as old as social; as well as the; as well as the;\n",
      "as well as in; as much as they; as much as possible; as well as the;\n",
      "as well as some; as simple as one; as well as the; as well as in; as\n",
      "definable as possible; as long as they; as well as their; as well as\n",
      "forecasting; as soon as possible; as inevitable as anything; as well\n",
      "as for; as well as for; as nebulous as the; as awkward as the; as well\n",
      "as the; as well as by; as well as those; as well as the; as well as\n",
      "an; as well as with; as well as the; as well as moral; as much as\n",
      "their; as well as that; as likely as not; as well as upon; as well as\n",
      "on; as well as upon; as long as all; as far as one; as long as the; as\n",
      "empty as the; as well as the; as well as the; as soon as they; as well\n",
      "as office; as speedily as possible; as well as of; as well as start;\n",
      "as well as behind; as much as for; as effectively as they; as\n",
      "important as it; as nearly as feasible; as well as form; as well as\n",
      "aesthetic; as well as ethical; as well as Impressionism; as well as\n",
      "the; as broad as the; as much as he; as arresting as a; as odd as the;\n",
      "as well as the; as soon as possible; as long as it; as impassive as\n",
      "Persian; as long as those; as importantly as his; as well as\n",
      "providing; as well as the; as well as vertically; as well as new; as\n",
      "well as certain; as well as the; as close as possible; as far as\n",
      "obtainable; as well as the; as important as the; as long as the; as\n",
      "satisfactory as those\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown \n",
    "hobbies_learned = nltk.Text(brown.words(categories = ['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r'<\\w*> <and> <other> <\\w*s>')\n",
    "hobbies_learned.findall(r'<as> <\\w*> <as> <\\w*>')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.889058Z",
     "start_time": "2024-04-20T12:18:50.429027Z"
    }
   },
   "id": "2b4e98daacedbb63",
   "execution_count": 146
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercises \n",
    "#### 1. Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95502eba563befe0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colourless\n"
     ]
    }
   ],
   "source": [
    "s = 'colorless' \n",
    "print(s[:4] + 'u' + s[4:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.891583Z",
     "start_time": "2024-04-20T12:18:50.889728Z"
    }
   },
   "id": "76a23c7b827e1613",
   "execution_count": 147
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9281da907ef951ce"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dish', 'run', 'nation', 'do', 'heat']\n"
     ]
    }
   ],
   "source": [
    "ex2_words = [w for w in 'dish-es, run-ning, nation-ality, un-do, pre-heat'.split(', ')]\n",
    "ex2_noaff = [ex2_words[0][:-3], ex2_words[1][:-5], ex2_words[2][:-6], ex2_words[3][-2:], ex2_words[4][-4:]]\n",
    "print(ex2_noaff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.894547Z",
     "start_time": "2024-04-20T12:18:50.892260Z"
    }
   },
   "id": "3f1bab5ab0e0ad45",
   "execution_count": 148
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string? \n",
    "I don't think so. I cannot use negative numbers as they remove chars and the lowest possible is then 0 which is the first char.\n",
    " \n",
    "Okay, I see it now. I thought about slicing but not about indexing. So it's possible to raise the error then. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232e2c1ec1fc3f3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "o\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "s = \"hello\"\n",
    "print(s[-6:])  # This will print 'hello'\n",
    "print(s[-100:])  # Still prints 'hello', as slicing is more forgiving\n",
    "print(s[-1])  # This will print 'o'\n",
    "print(s[-5])  # This will print 'h'\n",
    "# Accessing beyond the start (too far to the left)\n",
    "#print(s[-6])  # This will raise an IndexError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.897177Z",
     "start_time": "2024-04-20T12:18:50.895212Z"
    }
   },
   "id": "c1e07d4ad2481ab3",
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc4ba639f33690e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pes ol o tptenie\n",
      "' rn e oers\n",
      "rmalteubr hce\n",
      "ocsi yha\n",
      "lo \n"
     ]
    }
   ],
   "source": [
    "print(paranoid[::2])\n",
    "print(paranoid[10:5:-2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.900166Z",
     "start_time": "2024-04-20T12:18:50.897838Z"
    }
   },
   "id": "e5158f4a4b4754e1",
   "execution_count": 150
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result.\n",
    "It reverses a string, but why can it be reasonable? Perhaps if some text is reversed, it can reverse it back. Or to print some text so it's readable in mirrors. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "832f6cb4e71a2fad"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daeh ym ni secioV\n",
      "nekcihc nrobnu eht lla morF\n",
      "tser emos teg anyrt m'I\n",
      "?esion eht pots uoy dluoc esaelP\n",
      "Please could you stop the noise?\n",
      "I'm tryna get some rest\n",
      "From all the unborn chicken\n",
      "Voices in my head\n"
     ]
    }
   ],
   "source": [
    "print(paranoid[::-1])\n",
    "print(paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:50.902666Z",
     "start_time": "2024-04-20T12:18:50.900883Z"
    }
   },
   "id": "4d0c7290d472711",
   "execution_count": 151
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Describe the class of strings matched by the following regular expressions. \n",
    "1. ```[a-zA-Z]+```: '+' means one or more of previous item, in this case one or more of any letter, case doesn't matter ('cat', 'so') > any word \n",
    "2. ```[A-Z][a-z]*```: here case matters, so first it should be an upper one then zero or more of any lower case ('D', 'Dog') > any upper case word \n",
    "3. ```p[aeiou]{,2}t```: a sequence should start with 'p' and end with 't', then between there should be at most 2 vowels > too much output, replacing it with ```^p[aeiou]{,2}t$``` ('put', 'poet') \n",
    "4. ```\\d+(\\.\\d+)?```: one or more digits and zero or one ('?') of digits after the decimal point\n",
    "5. ```([^aeiou][aeiou][^aeiou])*```: zero or more instances of a chunk that doesn't start with a vowel then has one vowel and doen't end with the vowel, so its CVC* combinations (??)  -- huh? \n",
    "6. ```\\w+|[^\\w\\s]+```: any alphanumeric char OR something that doesn't start with any alphanumeric char and a white space -- anything that is not a space?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6166b84c0ec21f4e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Please} {could} {you} {stop} {the} {noise}?\n",
      "{I}'{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n",
      "{Please} could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{From} all the unborn chicken\n",
      "{Voices} in my head\n",
      "['pat', 'paut', 'peat', 'pet', 'piet', 'pit', 'poet', 'poot', 'pot', 'pout', 'put']\n",
      "[]\n",
      "{}P{}l{}e{}a{se }{}c{}o{}u{}l{}d{} {}y{}o{}u{} {}s{top}{} {}t{he }{}n{}o{}i{se?}{}\n",
      "{}I{}'{}m{} {}t{}r{}y{na get}{} {som}{}e{} {res}{}t{}\n",
      "{}F{rom al}{}l{} {}t{he }{}u{}n{bor}{}n{} {}c{hicken}{}\n",
      "{}V{}o{}i{ces in}{} {}m{}y{} {}h{}e{}a{}d{}\n",
      "{Please} {could} {you} {stop} {the} {noise}{?}\n",
      "{I}{'}{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r'[a-zA-Z]+', paranoid)\n",
    "nltk.re_show(r'[A-Z][a-z]*', paranoid)\n",
    "print([w for w in word_list if re.search(r'^p[aeiou]{,2}t$', w)])\n",
    "print([w for w in word_list if re.search(r'\\d+(\\.\\d+)?', w)])\n",
    "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', paranoid)\n",
    "nltk.re_show(r'\\w+|[^\\w\\s]+', paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:51.061057Z",
     "start_time": "2024-04-20T12:18:50.903391Z"
    }
   },
   "id": "c2f2afbe41377ed2",
   "execution_count": 152
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Write regular expressions to match the following classes of strings:\n",
    "\n",
    "1. A single determiner (assume that a, an, and the are the only determiners).\n",
    "2. An arithmetic expression using integers, addition, and multiplication, such as 2*3+8."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9abdfb7d784930"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please could you stop {the} noise?\n",
      "I'm tryna get some rest\n",
      "From all {the} unborn chicken\n",
      "Voices in my head\n",
      "What's that? (I may be paranoid, but not {an} android)\n",
      "What's that? (I may be paranoid, but not {an} android)\n",
      "When I am king\n",
      "You will be first against {the} wall\n",
      "With your opinion\n",
      "Which is of no consequence at all\n",
      "What's that? (I may be paranoid, but no android)\n",
      "What's that? (I may be paranoid, but no android)\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La, la\n",
      "Ambition makes you look pretty ugly\n",
      "Kicking, squealing, Gucci little piggy\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la\n",
      "You don't remember, you don't remember\n",
      "Why don't you remember my name?\n",
      "Off with his head, man, off with his head, man\n",
      "Why don't you remember my name?\n",
      "I guess he does\n",
      "Ah, oh, oh, oh\n",
      "Oh, oh, oh, oh\n",
      "Oh, oh\n",
      "Oh, oh\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From {a} great height\n",
      "From {a} great height, height\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From {a} great height\n",
      "From {a} great height, height\n",
      "that's it, sir, you're leaving\n",
      "The crackle of pigskin (rain down)\n",
      "(Come on rain down) {the} dust and {the} screaming\n",
      "The yuppies networking\n",
      "The panic, {the} vomit (from {a} great height)\n",
      "The panic, {the} vomit (from {a} great height)\n",
      "God loves his children\n",
      "God loves his children, yeah\n"
     ]
    }
   ],
   "source": [
    "paranoid_full_raw = open('paranoid_full.txt')\n",
    "paranoid_full = paranoid_full_raw.read()\n",
    "nltk.re_show(r'(\\ban?\\b)|(\\bthe\\b)', paranoid_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:51.064968Z",
     "start_time": "2024-04-20T12:18:51.061875Z"
    }
   },
   "id": "e31c146a846ca13",
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2+2+2+2+2}, {2+2}, {5*4}, {73}{-74+73}{-74}, {34}/{2}, {2*3+8}, banana, apple, DNA, {451}Fahrenheit\n",
      "{2+2+2+2+2}, {2+2}, {5*4}, {73-74+73-74}, {34/2}, {2*3+8}, banana, apple, DNA, {451}Fahrenheit\n"
     ]
    }
   ],
   "source": [
    "arithmetics_7b = \"2+2+2+2+2, 2+2, 5*4, 73-74+73-74, 34/2, 2*3+8, banana, apple, DNA, 451Fahrenheit\" # {451}Fahrenheit is picked in both cases\n",
    "\n",
    "nltk.re_show(r'-?\\d+(\\s*[\\+\\*]\\s*-?\\d+)*', arithmetics_7b) # ChatGPT\n",
    "nltk.re_show(r'([^\\sa-zA-Z,]*[\\+\\*]*)*[^\\s,a-zA-Z]', arithmetics_7b) # my version "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:51.067332Z",
     "start_time": "2024-04-20T12:18:51.065627Z"
    }
   },
   "id": "9d690a524a3d3102",
   "execution_count": 154
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8226bcde9bc96898"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK :: Natural Language Toolkit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK\n",
      "\n",
      "\n",
      "\n",
      "Documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK Documentation\n",
      "\n",
      "API Reference\n",
      "Example Usage\n",
      "Module Index\n",
      "Wiki\n",
      "FAQ\n",
      "Open Issues\n",
      "NLTK on GitHub\n",
      "\n",
      "Installation\n",
      "\n",
      "Installing NLTK\n",
      "Installing NLTK Data\n",
      "\n",
      "More\n",
      "\n",
      "Release Notes\n",
      "Contributing to NLTK\n",
      "NLTK Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Natural Language ToolkitÂ¶\n",
      "NLTK is a leading platform for building Python programs to work with human language data.\r\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical\r\n",
      "resources such as WordNet,\r\n",
      "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\r\n",
      "wrappers for industrial-strength NLP libraries,\r\n",
      "and an active discussion forum.\n",
      "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\r\n",
      "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\r\n",
      "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
      "NLTK has been called âa wonderful tool for teaching, and working in, computational linguistics using Python,â\r\n",
      "and âan amazing library to play with natural language.â\n",
      "Natural Language Processing with Python provides a practical\r\n",
      "introduction to programming for language processing.\r\n",
      "Written by the creators of NLTK, it guides the reader through the fundamentals\r\n",
      "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\r\n",
      "and more.\r\n",
      "The online version of the book has been been updated for Python 3 and NLTK 3.\r\n",
      "(The original Python 2 version is still available at https://www.nltk.org/book_1ed.)\n",
      "\n",
      "Some simple things you can do with NLTKÂ¶\n",
      "Tokenize and tag some text:\n",
      ">>> import nltk\r\n",
      ">>> sentence = \"\"\"At eight o'clock on Thursday morning\r\n",
      "... Arthur didn't feel very good.\"\"\"\r\n",
      ">>> tokens = nltk.word_tokenize(sentence)\r\n",
      ">>> tokens\r\n",
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning',\r\n",
      "'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\r\n",
      ">>> tagged = nltk.pos_tag(tokens)\r\n",
      ">>> tagged[0:6]\r\n",
      "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'),\r\n",
      "('Thursday', 'NNP'), ('morning', 'NN')]\r\n",
      "\n",
      "\n",
      "Identify named entities:\n",
      ">>> entities = nltk.chunk.ne_chunk(tagged)\r\n",
      ">>> entities\r\n",
      "Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'),\r\n",
      "           ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'),\r\n",
      "       Tree('PERSON', [('Arthur', 'NNP')]),\r\n",
      "           ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'),\r\n",
      "           ('very', 'RB'), ('good', 'JJ'), ('.', '.')])\r\n",
      "\n",
      "\n",
      "Display a parse tree:\n",
      ">>> from nltk.corpus import treebank\r\n",
      ">>> t = treebank.parsed_sents('wsj_0001.mrg')[0]\r\n",
      ">>> t.draw()\r\n",
      "\n",
      "\n",
      "\n",
      "NB. If you publish work that uses NLTK, please cite the NLTK book as\r\n",
      "follows:\n",
      "\n",
      "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  OâReilly Media Inc.\n",
      "\n",
      "\n",
      "\n",
      "Next StepsÂ¶\n",
      "\n",
      "Sign up for release announcements\n",
      "Join in the discussion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " source\n",
      "\n",
      "\n",
      "3.8.1\n",
      "\n",
      "\r\n",
      "                    Jan 02, 2023\r\n",
      "                \n",
      "\n",
      "\r\n",
      "                Â© 2023, NLTK Project\r\n",
      "            \n",
      "\r\n",
      "            created with Sphinx and NLTK Theme\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          PQs workshop (BCL 2024) | Maria Onoeva                      Maria Onoeva  Toggle navigation        about me   PQs workshop (BCL 2024)(current)   publications   projects   cv                     PQs workshop (BCL 2024) Our workshop at The Biennial of Czech Linguistics 2024   We are happy to announce that our workshop Polar (yes/no) questions: form, meaning and more has been accepted to The Biennial of Czech Linguistics. The Biennial 2024 is the first edition of a new conference taking place at the Faculty of Arts, Charles University on September 18-20, 2024. The concept of the conference builds on the model applied at the European level (the conference of Societas Linguistica Europaea) or in Germany (the conference of the Deutsche Gesellschaft fÃ¼r Sprachwissenschaft). Here you find more information about our workshop (CfP, general description, etc.) and the conference. In case of any questions contact us at mariia.razguliaeva.1@hu-berlin.de or onoevam@ff.cuni.cz. Workshop description This panel aims to bring together researchers who work on forms, meanings, and functions of polar questions (PQs) in their intra- and cross-linguistic variability. We invite a diverse range of submissions that draw upon theoretical observations, experimental results, corpus research, and other relevant perspectives. The goal is to establish a productive dialog between different approaches and gain new insights into the nature of PQs. It is planned to address the following research questions (the list is not exhaustive): 1) How do forms of PQs map to various facets of their meanings across languages? 2) Which contexts can be considered natural for certain PQ types? 3) How can the meaning of PQs be formalized and what predictions emerge from certain formalizations? 4) How are PQs processed by speakers, as well as during language acquisition and/or learning? Invited speaker    We are delighted to announce the invited speaker for our workshop - Tue Trinh, a senior researcher in the ERC project Speech Acts in Grammar and Discourse (SPAGAD) / Research Area 4 'Semantics & Pragmatics' at the Leibniz-Zentrum Allgemeine Sprachwissenschaft in Berlin. Tue works on many fascinating topics in syntax, semantics and pragmatics and, luckily for us, contributes greatly to the polar questions discussion. In some of the recent works, Tue explores a relation between NPIs and epistemic bias (Trinh 2023) or describes the differences between Vietnamese and English polar questions (Trinh 2024). The topic of the talk will be provided soon.              Call for papers Here is a summarized version of the call, for more visit the Biennial 2024 Call  Deadline: March 25, 2024 Platform: OpenReview (please register before submitting), the Biennial OpenReview page  Template: here  Our panel number: 16 One person can submit at most 3 abstracts to 2 workshops All abstracts must be anonymous and in the pdf format     Important dates Â      October 1, 2023: Deadline for submission of thematic workshop proposals   November 17, 2023: Notification of workshop acceptance   November 30, 2023: Call for abstracts to be issued   February 6, 2024: The abstract submission system has been launched.   March 25, 2024: Deadline for submission of abstracts   May 31, 2024: Final draft of the programme of workshops   June 30, 2024: Final draft programme of the Biennial   September 18-20, 2024: The Biennial of Czech Linguistics         Â© Copyright 2024 Maria Onoeva. Powered by Jekyll with al-folio theme. Hosted by GitHub Pages. Last updated: March 03, 2024.                      \n"
     ]
    }
   ],
   "source": [
    "def url_opener(link):\n",
    "    url = link \n",
    "    response = request.urlopen(url) \n",
    "    raw = response.read().decode('utf8')\n",
    "    ready_url = BeautifulSoup(raw, 'html.parser').get_text()\n",
    "    print(ready_url) \n",
    "    \n",
    "url_opener('http://nltk.org/')\n",
    "url_opener('https://mariaonoeva.github.io/Biennial2024/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:18:51.704288Z",
     "start_time": "2024-04-20T12:18:51.067958Z"
    }
   },
   "id": "ca2947c45db263da",
   "execution_count": 155
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.  Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "1. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multi-line regular expression, with inline comments, using the verbose flag (?x)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "622cd08fea2550f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load(my_text_raw): \n",
    "    my_text = open(my_text_raw)\n",
    "    my_text_read = my_text.read() \n",
    "    return my_text_read\n",
    "\n",
    "def punct_counter(my_text):\n",
    "    counter_list = []\n",
    "    punct = nltk.regexp_tokenize(load(my_text), r'[^\\w\\s\\d]')\n",
    "    for i in punct: \n",
    "        counter_list.append(punct.count(i))\n",
    "    ready_dict = dict(zip(punct, counter_list))\n",
    "    sorted_dict = dict(sorted(ready_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_dict.items()\n",
    "\n",
    "punct_counter('paranoid_full.txt')\n",
    "eng_HP = punct_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')\n",
    "ru_HP = punct_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1ru.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.268284Z",
     "start_time": "2024-04-20T12:18:51.705074Z"
    }
   },
   "id": "5c80419b6130c6c7",
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation      Count\n",
      "-------------  -------\n",
      ".                 6136\n",
      ",                 5658\n",
      "\"                 4758\n",
      "'                 3141\n",
      "-                 1990\n",
      "?                  754\n",
      "!                  474\n",
      ";                  135\n",
      ":                   69\n",
      ")                   33\n",
      "(                   30\n",
      "*                    2\n",
      "~                    1\n",
      "\\                    1\n",
      "Punctuation      Count\n",
      "-------------  -------\n",
      ",                10190\n",
      ".                 6355\n",
      "â                 4598\n",
      "-                 1038\n",
      "â¦                  805\n",
      "?                  761\n",
      "!                  620\n",
      "Â«                  222\n",
      "Â»                  221\n",
      ":                  140\n",
      "*                  117\n",
      "(                   13\n",
      ")                   13\n",
      ";                    3\n",
      "â                    1\n",
      "â                    1\n",
      "â                    1\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate \n",
    "headers = ['Punctuation', 'Count']\n",
    "\n",
    "print(tabulate(eng_HP, headers=headers))\n",
    "print(tabulate(ru_HP, headers=headers))\n",
    "\n",
    "# I want them side by side \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.275401Z",
     "start_time": "2024-04-20T12:19:01.269760Z"
    }
   },
   "id": "3c311df5b5574fa9",
   "execution_count": 157
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Harry Potter 1 punctuation: Eng and Ru \n",
    "##### Eng: \n",
    "- why are there 30 of '(' and 33 of ')'? \n",
    "- questions: 754\n",
    "##### Ru: \n",
    "- same for Ru for kavychki, but skobki are even\n",
    "- so many commas??? \n",
    "- questions: 761 > 7 more > pretty consistent, I can imagine contexts where several questions mark used to express anger or surprise "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7ead94457cbb77"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation ENG      Count    Punctuation RU      Count\n",
      ".                     6136    ,                   10190\n",
      ",                     5658    .                    6355\n",
      "\"                     4758    â                    4598\n",
      "'                     3141    -                    1038\n",
      "-                     1990    â¦                     805\n",
      "?                      754    ?                     761\n",
      "!                      474    !                     620\n",
      ";                      135    Â«                     222\n",
      ":                       69    Â»                     221\n",
      ")                       33    :                     140\n",
      "(                       30    *                     117\n",
      "*                        2    (                      13\n",
      "~                        1    )                      13\n",
      "\\                        1    ;                       3\n",
      "                              â                       1\n",
      "                              â                       1\n",
      "                              â                       1\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT to display the tables side by side\n",
    "# Generate table strings\n",
    "table1 = tabulate(eng_HP, headers=['Punctuation ENG', 'Count'], tablefmt='plain')\n",
    "table2 = tabulate(ru_HP, headers=['Punctuation RU', 'Count'], tablefmt='plain')\n",
    "\n",
    "# Split tables into lines\n",
    "lines1 = table1.split('\\n')\n",
    "lines2 = table2.split('\\n')\n",
    "\n",
    "# Determine the max width of the first table\n",
    "max_width = max(len(line) for line in lines1)\n",
    "\n",
    "# Determine the longer table for iteration\n",
    "longest_table_length = max(len(lines1), len(lines2))\n",
    "\n",
    "# Print tables side by side, handling uneven number of rows\n",
    "for i in range(longest_table_length):\n",
    "    line1 = lines1[i] if i < len(lines1) else \"\"\n",
    "    line2 = lines2[i] if i < len(lines2) else \"\"\n",
    "    print(f\"{line1.ljust(max_width)}    {line2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.280632Z",
     "start_time": "2024-04-20T12:19:01.276539Z"
    }
   },
   "id": "cc8336f6f19a8953",
   "execution_count": 158
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9. Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "2. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the following kinds of expression: monetary amounts; dates; names of people and organizations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc0647d4a5dd8fff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200$}, {363524$}, {587$}, {65â¬}, {8746CZK}, {8â½}, {9382â½}, {87362513537CZK}, Grand Theft Auto V, Corpus paper, April, Thursday, 76F, 17C\n"
     ]
    }
   ],
   "source": [
    "# monetary amounts? \n",
    "monetary_amounts = \"200$, 363524$, 587$, 65â¬, 8746CZK, 8â½, 9382â½, 87362513537CZK, Grand Theft Auto V, Corpus paper, April, Thursday, 76F, 17C\"\n",
    "money_pattern = r'\\d+([\\$â¬â½]|CZK)+' \n",
    "\n",
    "nltk.re_show(money_pattern, monetary_amounts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.283112Z",
     "start_time": "2024-04-20T12:19:01.281358Z"
    }
   },
   "id": "6ca3e7d8db41177",
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2024-04-04}, {2024-04-05}, Your Top Songs 2023, {2024-04-06}, pinguin, {2024-04-07}, {2024-04-08}, Ice-cream, {2024-04-09}, {2024-04-10}, SnÄÅ¾ka\n",
      "2024-04-04, 2024-04-05, {Y}our {T}op {S}ongs 2023, 2024-04-06, pinguin, 2024-04-07, 2024-04-08, {I}ce-cream, 2024-04-09, 2024-04-10, {S}nÄÅ¾ka\n"
     ]
    }
   ],
   "source": [
    "# dates\n",
    "dates_more = '2024-04-04, 2024-04-05, Your Top Songs 2023, 2024-04-06, pinguin, 2024-04-07, 2024-04-08, Ice-cream, 2024-04-09, 2024-04-10, SnÄÅ¾ka'\n",
    "dates_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "nltk.re_show(dates_pattern, dates_more)\n",
    "\n",
    "# names of people and organizations\n",
    "names_pattern = r'[A-Z]+'\n",
    "nltk.re_show(names_pattern, dates_more)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.289933Z",
     "start_time": "2024-04-20T12:19:01.287578Z"
    }
   },
   "id": "1b58f300e8e7699f",
   "execution_count": 160
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 10. Rewrite the following loop as a list comprehension:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84957ac758b2034"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]\n"
     ]
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "result = []\n",
    "for word in sent:\n",
    "    word_len = (word, len(word))\n",
    "    result.append(word_len)\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.293054Z",
     "start_time": "2024-04-20T12:19:01.290743Z"
    }
   },
   "id": "9b0ca92465f42ddb",
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]\n"
     ]
    }
   ],
   "source": [
    "result_1 = [(word, len(word)) for word in sent] \n",
    "print(result_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.296543Z",
     "start_time": "2024-04-20T12:19:01.293783Z"
    }
   },
   "id": "7aac8030f89ad32f",
   "execution_count": 162
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 11. Define a string raw containing a sentence of your own choosing. Now, split raw on some character other than space, such as 's'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "113d57c6d2514ec0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Don't be a drag, just be a queen\", \"Whether you're broke or evergreen\", \"You're Black, white, beige, chola descent\", \"You're Lebanese, you're Orient'\", \"Whether life's disabilities left you outcast, bullied, or teased\", 'Rejoice and love yourself today', \"'Cause, baby, you were born this way\"]\n"
     ]
    }
   ],
   "source": [
    "born_this_way = \"\"\"Don't be a drag, just be a queen\n",
    "Whether you're broke or evergreen\n",
    "You're Black, white, beige, chola descent\n",
    "You're Lebanese, you're Orient'\n",
    "Whether life's disabilities left you outcast, bullied, or teased\n",
    "Rejoice and love yourself today\n",
    "'Cause, baby, you were born this way\"\"\" \n",
    "\n",
    "print(born_this_way.split('\\n'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.299693Z",
     "start_time": "2024-04-20T12:19:01.297411Z"
    }
   },
   "id": "ab29e93a45589d1d",
   "execution_count": 163
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 12. Write a for loop to print out the characters of a string, one per line."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d836e1587f2e8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "D\n",
      "N\n",
      "A\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "b\n",
      "o\n",
      "r\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "dna = \"Same DNA, but born this way\"\n",
    "for char in dna: \n",
    "    print(char)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.302592Z",
     "start_time": "2024-04-20T12:19:01.300591Z"
    }
   },
   "id": "32b57d66464fe1eb",
   "execution_count": 164
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 13. What is the difference between calling split on a string with no argument or with ' ' as the argument, e.g. sent.split() versus sent.split(' ')? What happens when the string being split contains tab characters, consecutive space characters, or a sequence of tabs and spaces? (In IDLE you will need to use '\\t' to enter a tab character.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110d93060b9aa65a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Same', 'DNA,', 'but', 'born', 'this', 'way']\n",
      "['Same', 'DNA,', 'but', 'born', 'this', 'way']\n",
      "['Same DNA, but born this way']\n"
     ]
    }
   ],
   "source": [
    "print(dna.split()) # space split\n",
    "print(dna.split(' ')) # same as the empty argument \n",
    "print(dna.split('\\t')) # no change because there is no tab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.305314Z",
     "start_time": "2024-04-20T12:19:01.303299Z"
    }
   },
   "id": "264bab69f5219b23",
   "execution_count": 165
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 14. Create a variable words containing a list of words. Experiment with words.sort() and sorted(words). What is the difference?\n",
    "https://www.geeksforgeeks.org/python-difference-between-sorted-and-sort/ -- cool! "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad074d4668753642"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['DNA,', 'Same', 'born', 'but', 'this', 'way']\n"
     ]
    }
   ],
   "source": [
    "dna_split = dna.split()\n",
    "print(dna_split.sort()) # none? why? > as per documentation returns None and changes the initial list \n",
    "print(sorted(dna_split)) # only returns the sorted list and makes no changes "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.307836Z",
     "start_time": "2024-04-20T12:19:01.306013Z"
    }
   },
   "id": "4cc79cf145c07a25",
   "execution_count": 166
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 15.  Explore the difference between strings and integers by typing the following at a Python prompt: \"3\" * 7 and 3 * 7. Try converting between strings and integers using int(\"3\") and str(3)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65a5266eae4ba850"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333\n",
      "21\n",
      "21\n",
      "3333333\n"
     ]
    }
   ],
   "source": [
    "print(\"3\"*7)\n",
    "print(3*7)\n",
    "print(int(\"3\")*7)\n",
    "print(str(3)*7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.310793Z",
     "start_time": "2024-04-20T12:19:01.308547Z"
    }
   },
   "id": "d89aef26c435e9ed",
   "execution_count": 167
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 16. Use a text editor to create a file called prog.py containing the single line monty = 'Monty Python'. Next, start up a new session with the Python interpreter, and enter the expression monty at the prompt. You will get an error from the interpreter. Now, try the following (note that you have to leave off the .py part of the filename).  This time, Python should return with a value. You can also try import prog, in which case Python should be able to evaluate the expression prog.monty at the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30a5bec7dd5fc3ba"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Monty Python'"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prog import monty\n",
    "monty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.313774Z",
     "start_time": "2024-04-20T12:19:01.311493Z"
    }
   },
   "id": "1d734dbb7e07359f",
   "execution_count": 168
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 17. What happens when the formatting strings %6s and %-6s are used to display strings that are longer than six characters?\n",
    "I don't get this... "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e39b9e25de659cdb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number is : thisisaword\n",
      "Number is : thisisaword\n",
      "Number is :  aword\n",
      "Number is : aword \n"
     ]
    }
   ],
   "source": [
    "print(\"Number is : %6s\" % 'thisisaword')\n",
    "print(\"Number is : %-6s\" % 'thisisaword')\n",
    "print(\"Number is : %6s\" % 'aword')\n",
    "print(\"Number is : %-6s\" % 'aword')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.316910Z",
     "start_time": "2024-04-20T12:19:01.314508Z"
    }
   },
   "id": "325095e965e69c0a",
   "execution_count": 169
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 18. Read in some text from a corpus, tokenize it, and print the list of all wh-word types that occur. (wh-words in English are used in questions, relative clauses and exclamations: who, which, what, and so on.) Print them in order. Are any words duplicated in this list, because of the presence of case distinctions or punctuation?\n",
    "Woooow, I did it already in Chapter 2 but in a different way! \n",
    "- Well, I have some non-wh-words (whisperers, whirled, wheel, etc.), should I remove them? How to that without a wh-words list as in Chapter 2? \n",
    "- At the beginning I wanted to sum all duplicates, but now I sort of like that I have upper and lower case as separate lines because it shows different uses (interrogative and relative wh-words) \n",
    "- Updated wh_counter function, now it gives a table right away\n",
    "- idk i'll think about it later, the list way from Chapter 2 was easier in a way "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a6aca41587c28"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wh-word       Count\n",
      "--  ----------  -------\n",
      " 0  When             20\n",
      " 1  when             13\n",
      " 2  what             13\n",
      " 3  who              10\n",
      " 4  where             8\n",
      " 5  What              8\n",
      " 6  which             6\n",
      " 7  while             6\n",
      " 8  Where             6\n",
      " 9  whether           4\n",
      "10  While             3\n",
      "11  whatever          3\n",
      "12  white             2\n",
      "13  wheel             1\n",
      "14  whisperers        1\n",
      "15  whistled          1\n",
      "16  Who               1\n",
      "17  whole             1\n",
      "18  Whether           1\n",
      "19  Whispers          1\n",
      "20  Wheeling          1\n",
      "21  whirled           1\n",
      "22  Which             1\n",
      "23  why               1\n",
      "24  whirl             1\n",
      "25  Whatever          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "def wh_counter(my_text):\n",
    "    counter_list = []\n",
    "    wh_raw = nltk.regexp_tokenize(load(my_text), r'^[Ww]h[a-z]+')\n",
    "    for i in wh_raw: \n",
    "        counter_list.append(wh_raw.count(i))\n",
    "    ready_dict = dict(zip(wh_raw, counter_list))\n",
    "    sorted_dict = dict(sorted(ready_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    output_wh_counter = pd.DataFrame(sorted_dict.items())\n",
    "    headers_wh = ['Wh-word', 'Count']\n",
    "    print(tabulate(output_wh_counter, headers=headers_wh))\n",
    "\n",
    "wh_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.341838Z",
     "start_time": "2024-04-20T12:19:01.317568Z"
    }
   },
   "id": "889c3256da8edb60",
   "execution_count": 170
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 19. Create a file consisting of words and (made up) frequencies, where each line consists of a word, the space character, and a positive integer, e.g. fuzzy 53. Read the file into a Python list using open(filename).readlines(). Next, break each line into its two fields using split(), and convert the number into an integer using int(). The result should be a list of the form: [['fuzzy', 53], ...]. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84db07c177ea017"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['current', 56], ['file', 32], ['heat', 85], ['moment', 12], ['by', 47], ['my', 36], ['side', 93]]\n"
     ]
    }
   ],
   "source": [
    "words_19 = load('chap3_ex19.txt')\n",
    "ex19 = [item.split() for item in words_19.split('\\n')]\n",
    "ex19_1 = [[item[0], int(item[1])] for item in ex19]\n",
    "\n",
    "print(ex19_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:01.350077Z",
     "start_time": "2024-04-20T12:19:01.343643Z"
    }
   },
   "id": "b13f0be8e7b93c08",
   "execution_count": 171
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 20. Write code to access a favorite webpage and extract some text from it. For example, access a weather site and extract the forecast top temperature for your town or city today. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89abf166736c7d66"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'PragueDay by day forecastLast updated today at 14:00Today, Light rain and a moderate breezeLight RainLight Rain, High7Â° 45Â°Low-2Â° 28Â°, Wind speed15 mph23 km/h N15 mph23 km/hNortherlyLight rain and a moderate breezeSunday\\xa0'"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def url_opener_Return(link):\n",
    "    url = link \n",
    "    response = request.urlopen(url) \n",
    "    raw = response.read().decode('utf8')\n",
    "    ready_url = BeautifulSoup(raw, 'html.parser').get_text()\n",
    "    return ready_url\n",
    "    \n",
    "url_opener_Return('https://www.bbc.com/weather/3067696')[1375:1596]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:02.144508Z",
     "start_time": "2024-04-20T12:19:01.352386Z"
    }
   },
   "id": "f867ef092c60a8e2",
   "execution_count": 172
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 21. Write a function unknown() that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using re.findall()) and remove any items from this set that occur in the Words Corpus (nltk.corpus.words). Try to categorize these words manually and discuss your findings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9b8229dbd005df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def unknown(link):\n",
    "    link_text = url_opener_Return(link)\n",
    "    lower_all_words = [w.lower() for w in nltk.corpus.words.words()]\n",
    "    list_words = [w.lower() for w in word_tokenize(link_text) if w.isalpha()]\n",
    "    final_list = []\n",
    "    for word in list_words:\n",
    "        if word not in lower_all_words:\n",
    "            final_list.append(word)    \n",
    "    print(set(final_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:02.147857Z",
     "start_time": "2024-04-20T12:19:02.145334Z"
    }
   },
   "id": "2b6ecfde30a4603d",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'things', 'logo', 'rights', 'agreementfan', 'gamespot', 'breakdownmore', 'trademarks', 'rpg', 'futureimmerse', 'years', 'edgerunners', 'reboot', 'morewatch', 'libertyshowsedgerunnerscommunityforumsdiscordcosplay', 'addressenter', 'projekt', 'declarationredmodenglishenglishÑÑÑÑÐºÐ¸Ð¹deutschpolskiportuguÃªs', 'countries', 'rewardsmerchandisemediasupportcd', 'policycareersuser', 'cyberpunk', 'games', 'trailerlearn', 'netrunner', 'offers', 'onterms', 'policysubmitfind', 'email', 'routes', 'br', 'franÃ§aisespaÃ±olespaÃ±ol', 'guidesbuild', 'italianoæ¥æ¬èªíêµ­ì´ç®ä½ä¸­æç¹é«ä¸­æØ§ÙØ¹Ø±Ø¨ÙØ©buy', 'morelearn', 'stories', 'plannergame', 'cd', 'moregamescyberpunk', 'bookletmoreupdate', 'announcements', 'guidelinescookie', 'storyline', 'redenenglishÑÑÑÑÐºÐ¸Ð¹deutschpolskiportuguÃªs', 'gx', 'experiencelearn', 'eurogamerget', 'mx'}\n"
     ]
    }
   ],
   "source": [
    "unknown('https://www.cyberpunk.net/us/en/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:03.226059Z",
     "start_time": "2024-04-20T12:19:02.148555Z"
    }
   },
   "id": "50a233d3d0f7599c",
   "execution_count": 174
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 22. Examine the results of processing the URL http://news.bbc.co.uk/ using the regular expressions suggested above. You will see that there is still a fair amount of non-textual data there, particularly Javascript commands. You may also find that sentence breaks have not been properly preserved. Define further regular expressions that improve the extraction of text from this web page."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7156b0883f912dd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Home} - {B}{B}{C} {News}{B}{B}{C} {Homepage}{Skip} to content{Accessibility} {Help}{Your} account{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{More} menu{More} menu{Search} {B}{B}{C}{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{Culture}{Future}{Music}{T}{V}{Weather}{Sounds}{Close} menu{B}{B}{C} {News}{Menu}{Home}{Israel}-{Gaza} war{War} in {Ukraine}{India} {Election} 2024{Climate}{Video}{World}{U}{K}{Business}{Tech}{More}{Science}{Entertainment} & {Arts}{Health}{World} {News} {T}{V}{In} {Pictures}{B}{B}{C} {Verify}{Newsbeat}{Sign} {In} {Banner}{Discover} your {B}{B}{C}{Sign} in or create an account to watch, listen and join in{Sign} inor{Register}{Close} sign in banner{B}{B}{C} {News}{An} audible sigh of relief in the {Middle} {East}{The} latest round in the longstanding, dangerous rivalry between {Israel} and {Iran} seems over for now, {Lyse} {Doucet} writes.{Attribution}{Middle} {East}{Posted}10 hours ago10h{Live}.Â {Iran} downplays presumed {Israeli} attack but vows response to any 'decisive action'{Attribution}{Middle} {East}{Explosion} hits {Iraq} base housing pro-{Iranian} militia{Attribution}{Middle} {East}{Posted}1 hour ago1h{U}{K}'s largest indoor arena opens with big plans{Attribution}{Entertainment} & {Arts}{Posted}7 hours ago7h{Closure} of four rural primary schools postponed{Attribution}{Northern} {Ireland}{Posted}5 hours ago5h{How} {Taylor} {Swift} captured modern dating despair{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Baby} {Reindeer} star on 'role of a lifetime' in true crime drama{Attribution}{Entertainment} & {Arts}{Posted}9 hours ago9h{Man} who set fire to himself near {Trump} trial dies{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Three} men killed in retail park car crash named{Attribution}{London}{Posted}3 hours ago3h{Being} {Jewish} 'never provocative', says {Home} {Office}{Attribution}{London}{Posted}18 minutes ago18min{Former} {M}{Ps} hoping for a comeback at the next election{Attribution}{U}{K} {Politics}{Posted}8 hours ago8h{American} {Idol} singer {Mandisa} dies aged 47{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{An} attack on women that has devastated {Australia}{Attribution}{Australia}{Posted}19 hours ago19h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Northern} {Ireland}{An} audible sigh of relief in the {Middle} {East}{The} latest round in the longstanding, dangerous rivalry between {Israel} and {Iran} seems over for now, {Lyse} {Doucet} writes.{Attribution}{Middle} {East}{Posted}10 hours ago10h{Live}.Â {Iran} downplays presumed {Israeli} attack but vows response to any 'decisive action'{Attribution}{Middle} {East}{People} avoid drinking over lack of public toilets{Attribution}{Wales}{Posted}4 hours ago4h{Explosion} hits {Iraq} base housing pro-{Iranian} militia{Attribution}{Middle} {East}{Posted}1 hour ago1h{U}{K}'s largest indoor arena opens with big plans{Attribution}{Entertainment} & {Arts}{Posted}7 hours ago7h{How} {Taylor} {Swift} captured modern dating despair{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Baby} {Reindeer} star on 'role of a lifetime' in true crime drama{Attribution}{Entertainment} & {Arts}{Posted}9 hours ago9h{How} play helped girl with arthritis to laugh again{Attribution}{Wales}{Posted}5 hours ago5h{Man} who set fire to himself near {Trump} trial dies{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Three} men killed in retail park car crash named{Attribution}{London}{Posted}3 hours ago3h{Being} {Jewish} 'never provocative', says {Home} {Office}{Attribution}{London}{Posted}18 minutes ago18min{Former} {M}{Ps} hoping for a comeback at the next election{Attribution}{U}{K} {Politics}{Posted}8 hours ago8h{American} {Idol} singer {Mandisa} dies aged 47{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Wales}{An} audible sigh of relief in the {Middle} {East}{The} latest round in the longstanding, dangerous rivalry between {Israel} and {Iran} seems over for now, {Lyse} {Doucet} writes.{Attribution}{Middle} {East}{Posted}10 hours ago10h{Live}.Â {Iran} downplays presumed {Israeli} attack but vows response to any 'decisive action'{Attribution}{Middle} {East}{Explosion} hits {Iraq} base housing pro-{Iranian} militia{Attribution}{Middle} {East}{Posted}1 hour ago1h{U}{K}'s largest indoor arena opens with big plans{Attribution}{Entertainment} & {Arts}{Posted}7 hours ago7h{How} {Taylor} {Swift} captured modern dating despair{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Baby} {Reindeer} star on 'role of a lifetime' in true crime drama{Attribution}{Entertainment} & {Arts}{Posted}9 hours ago9h{Man} who set fire to himself near {Trump} trial dies{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Three} men killed in retail park car crash named{Attribution}{London}{Posted}3 hours ago3h{Being} {Jewish} 'never provocative', says {Home} {Office}{Attribution}{London}{Posted}18 minutes ago18min{Former} {M}{Ps} hoping for a comeback at the next election{Attribution}{U}{K} {Politics}{Posted}8 hours ago8h{American} {Idol} singer {Mandisa} dies aged 47{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{An} attack on women that has devastated {Australia}{Attribution}{Australia}{Posted}19 hours ago19h'{People} love my {London} {Marathon} costume - but animals are confused'{Attribution}{Newsbeat}{Posted}9 hours ago9h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Scotland}{An} audible sigh of relief in the {Middle} {East}{The} latest round in the longstanding, dangerous rivalry between {Israel} and {Iran} seems over for now, {Lyse} {Doucet} writes.{Attribution}{Middle} {East}{Posted}10 hours ago10h{Live}.Â {Iran} downplays presumed {Israeli} attack but vows response to any 'decisive action'{Attribution}{Middle} {East}{Explosion} hits {Iraq} base housing pro-{Iranian} militia{Attribution}{Middle} {East}{Posted}1 hour ago1h{U}{K}'s largest indoor arena opens with big plans{Attribution}{Entertainment} & {Arts}{Posted}7 hours ago7h{How} {Taylor} {Swift} captured modern dating despair{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Baby} {Reindeer} star on 'role of a lifetime' in true crime drama{Attribution}{Entertainment} & {Arts}{Posted}9 hours ago9h{Man} who set fire to himself near {Trump} trial dies{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Three} men killed in retail park car crash named{Attribution}{London}{Posted}3 hours ago3h{Being} {Jewish} 'never provocative', says {Home} {Office}{Attribution}{London}{Posted}18 minutes ago18min{Former} {M}{Ps} hoping for a comeback at the next election{Attribution}{U}{K} {Politics}{Posted}8 hours ago8h{American} {Idol} singer {Mandisa} dies aged 47{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{An} attack on women that has devastated {Australia}{Attribution}{Australia}{Posted}19 hours ago19h'{People} love my {London} {Marathon} costume - but animals are confused'{Attribution}{Newsbeat}{Posted}9 hours ago9h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {England}{An} audible sigh of relief in the {Middle} {East}{The} latest round in the longstanding, dangerous rivalry between {Israel} and {Iran} seems over for now, {Lyse} {Doucet} writes.{Attribution}{Middle} {East}{Posted}10 hours ago10h{Live}.Â {Iran} downplays presumed {Israeli} attack but vows response to any 'decisive action'{Attribution}{Middle} {East}{Explosion} hits {Iraq} base housing pro-{Iranian} militia{Attribution}{Middle} {East}{Posted}1 hour ago1h{U}{K}'s largest indoor arena opens with big plans{Attribution}{Entertainment} & {Arts}{Posted}7 hours ago7h{How} {Taylor} {Swift} captured modern dating despair{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{Baby} {Reindeer} star on 'role of a lifetime' in true crime drama{Attribution}{Entertainment} & {Arts}{Posted}9 hours ago9h{Man} who set fire to himself near {Trump} trial dies{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Three} men killed in retail park car crash named{Attribution}{London}{Posted}3 hours ago3h{Being} {Jewish} 'never provocative', says {Home} {Office}{Attribution}{London}{Posted}18 minutes ago18min{Former} {M}{Ps} hoping for a comeback at the next election{Attribution}{U}{K} {Politics}{Posted}8 hours ago8h{American} {Idol} singer {Mandisa} dies aged 47{Attribution}{Entertainment} & {Arts}{Posted}3 hours ago3h{An} attack on women that has devastated {Australia}{Attribution}{Australia}{Posted}19 hours ago19h'{People} love my {London} {Marathon} costume - but animals are confused'{Attribution}{Newsbeat}{Posted}9 hours ago9h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for the {U}{K}{Israel} and {Iran}{Bowen}: {Crisis} shows how badly {Iran} and {Israel} understand each other{Attribution}{Middle} {East}{Posted}1 day ago1d{B}{B}{C} {Verify} examines video from {Israel}'s attack on {Iran}. {Video}, 00:01:13{B}{B}{C} {Verify} examines video from {Israel}'s attack on {Iran}{Attribution}{Middle} {East}{Posted}18 hours ago18h1:13{Attack} sends message to {Iran} but {Israelis} divided over response{Attribution}{Middle} {East}{Posted}1 day ago1d{Isfahan} - strategic {Iranian} city where explosions heard{Attribution}{Middle} {East}{Posted}19 hours ago19h{Why} have {Israel} and {Iran} attacked each other?{Attribution}{Middle} {East}{Posted}1 day ago1d{Features} and analysis{Everything} you need to know about the 2024 {London} {Marathon}{Tributes} will be paid to {Kelvin} {Kiptum}, a world record could be set and famous faces take to the start line - here's everything you need to know about this year's {London} {Marathon}.{Attribution}{Athletics}{Posted}4 hours ago4h{After} hunt for impartiality, who are the 12 {Trump} jurors?{Attribution}{U}{S} & {Canada}{Posted}11 hours ago11h{Gold} heist spotlights illegal {U}{S}-{Canada} gun trade{Attribution}{U}{S} & {Canada}{Posted}11 hours ago11h{The} {Papers}: '{World} waits on {Iran}' and {Sunak} gets tough on benefits{Attribution}{The} {Papers}{Posted}6 hours ago6h{From} {Whats}{App} to {Greggs} - why is tech going down more?{Attribution}{Technology}{Posted}8 hours ago8h{Everything} we know about {Quentin} {Tarantino}'s 10th and final film{Attribution}{Culture}{Posted}21 hours ago21h{Disasters}, dancers and a {Duke}: {Photos} of the week{Attribution}{In} {Pictures}{Posted}7 hours ago7h{B}{B}{C} {News} app{Top} stories, breaking news, live reporting, and follow news topics that match your interests{Download} now{Most} watched1{One}-minute {World} {News}2{B}{B}{C} {World} {Service}3{B}{B}{C} {Verify} examines video from {Israel}'s attack on {Iran}4{Surfer} {Sebastian} {Steudtner} rides 28.57m wave5{B}{B}{C} {Persian} sent footage of {Isfahan} explosions{Also} in news{Chess} master plays 58 hours straight in {Times} {Square} to beat marathon record{The} 29-year-old chess master plays for 58 consecutive hours and counting on {New} {York}'s {Times} {Square}.{Attribution}{Africa}{Posted}8 hours ago8h{Some} {Wales} roads to revert to 30mph after backlash{Attribution}{Wales}{Posted}16 hours ago16h{App} to cut {E}{U} border queues won't be ready in time{Attribution}{Business}{Posted}14 hours ago14h{Met} {Police} apologises for 'openly {Jewish}' comment{Attribution}{London}{Posted}17 hours ago17h{B}{B}{C} presenter reports racist abuse on {London} train{Attribution}{U}{K}{Posted}16 hours ago16h{How} 500 from island of {Newfoundland} ended up on same cruise by coincidence. {Video}, 00:01:49{How} 500 from island of {Newfoundland} ended up on same cruise by coincidence{Attribution}{U}{S} & {Canada}{Posted}14 hours ago14h1:49{Nato} pledges more advanced air defences to {Ukraine}{Attribution}{Europe}{Posted}16 hours ago16h{Sport}{Live}.Â {Watch}: {Scottish} {Cup} - {Kuhn} slots {Celtic} level against {Aberdeen}{Watch} live {B}{B}{C} {One} {Scotland} coverage, listen to {Sportsound} commentary and follow live text updates as {Scottish} {Cup} holders {Celtic} meet {Aberdeen} in the semi-finals.{Attribution}{Scottish}{Live}.Â {E}{F}{L}: {Leicester} 1-0 {West} {Brom} - {Ndidi} gives {Foxes} lead{Attribution}{Championship}{Live}.Â {Women}'s {Champions} {League}: {Barcelona} 0-0 {Chelsea} - semi-final first leg under way{Attribution}{Women}'s {Football}{Live}.Â {Watch}: {World} {Snooker} {Championship} - {Brecel} leads {Gilbert} & {Jones} extends lead over {Zhang}{Attribution}{Snooker}{Live}.Â {County} {Championship}, day two - radio & text{Attribution}{Cricket}{Live}.Â {Watch}: {Diamond} {League} {Xiamen} - {G}{B}'s {Hussey} & {U}{S}{A}'s {Richardson} in action{Attribution}{Athletics}{Live}.Â {W}{S}{L}: {Liverpool} lead bottom side {Bristol} {City} 1-0{Attribution}{Women}'s {Football}{View} more{Most} read1{An} audible sigh of relief in the {Middle} {East}2{Three} men killed in retail park car crash named3{What} we know about {Israel}'s missile attack on {Iran}4{Man} who set fire to himself near {Trump} trial dies5'{Apocalyptic}' {Dubai} floods shake picture-perfect city6{How} {Taylor} {Swift} captured modern dating despair7{Explosion} hits {Iraq} base housing pro-{Iranian} militia8{Did} cloud seeding cause the {Dubai} flooding?9{U}{S} {Congress} close to passing long-awaited {Ukraine} aid10{Pub} dating back to 1500s badly damaged in fire{More} news on i{Player} and {Sounds}{Watch} live on i{Player}{U}{S} calls for calm between {Israel} and {Iran}13 {Times} {Taylor} {Swift} {Made} {History}. {Video}, 21 minutes13 {Times} {Taylor} {Swift} {Made} {History}{Attribution}{B}{B}{C} {News}({De}?) {Escalation} in the {Middle} {East}. {Audio}, 33 minutes({De}?) {Escalation} in the {Middle} {East}{Attribution}{B}{B}{C} {News}{B}{B}{C} {News} emails{Get} a range of {B}{B}{C} {News} newsletters delivered straight to your inbox throughout the week{Sign} up now{Elsewhere} on the {B}{B}{C}{Ready} to rock through time with the {Doctor} and {Ruby}?{Your} exclusive sneak peek at the new series of {Doctor} {Who}.{Attributioni}{Player}{How} {Taylor} {Swift} conquered the media{Attribution}{Sounds}{Who} will become {Sir} {Alan} {Sugar}'s next business partner?{Attributioni}{Player}{Four} and a half hours of tunes to soundtrack your run!{Attribution}{Sounds}{Alexander} {Mc}{Queen}: from private snaps to iconic photos{Attributioni}{Player}{In} 2008, {India} and {Bangladesh} were reconnected by train after 43 years{Attribution}{Sounds}{Fancy} a film night tonight?{Attributioni}{Player}{Tackling} it {Together}{Who} gets 15 hours of free childcare and how do {I} apply?{Attribution}{Family} & {Education}{Posted}2 {April}2 {Apr}{Childcare} shortage worsens as costs rise â report{Attribution}{Family} & {Education}{Posted}19 {March}19 {Mar}{Can} you afford to take your children on days out?{Attribution}{Wales}{Posted}30 {March}30 {Mar}{Mum} wishing son's life away in free childcare wait{Attribution}{Wales}{Posted}4 {April}4 {Apr}{View} more{Around} the {U}{K}{Three} men killed in retail park car crash identified{Attribution}{London}{Posted}3 hours ago3h{Closure} of four rural primary schools postponed{Attribution}{Northern} {Ireland}{Posted}5 hours ago5h{Scottish} {Greens} to vote on {S}{N}{P} power-sharing deal after climate target ditched{Attribution}{Scotland} {Politics}{Posted}20 minutes ago20min{Welsh} ministers 'put hands up' over 20mph rule{Attribution}{Wales}{Posted}16 hours ago16h{Find} your regional news{Instagram}{Tik}{Tok}{Facebook}{X}{News} alerts{Report} an issue{Send} a story{Why} you can trust {B}{B}{C} {News}{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{Culture}{Future}{Music}{T}{V}{Weather}{Sounds}{Terms} of {Use}{About} the {B}{B}{C}{Privacy} {Policy}{Cookies}{Accessibility} {Help}{Parental} {Guidance}{Contact} the {B}{B}{C}{Get} {Personalised} {Newsletters}{Why} you can trust the {B}{B}{C}{Advertise} with usÂ© 2024 {B}{B}{C}. {The} {B}{B}{C} is not responsible for the content of external sites. {Read} about our approach to external linking.\n"
     ]
    }
   ],
   "source": [
    "bbc_web = url_opener_Return('http://news.bbc.co.uk/')\n",
    "nltk.re_show(r'[A-Z][a-z]*', bbc_web)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.479143Z",
     "start_time": "2024-04-20T12:19:03.227093Z"
    }
   },
   "id": "c6e867574b2d99b7",
   "execution_count": 175
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 23. Are you able to write a regular expression to tokenize text in such a way that the word don't is tokenized into do and n't? Explain why this regular expression won't work: Â«n't|\\w+Â».\n",
    "It works, but it also matches all dos as in 'down' etc. Can I fix it? -- yes! using lookahead '?=n\\'t'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf031c9f68cd902"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please could you stop the noise?\n",
      "I'm tryna get some rest\n",
      "From all the unborn chicken\n",
      "Voices in my head\n",
      "What's that? (I may be paranoid, but not an android)\n",
      "What's that? (I may be paranoid, but not an android)\n",
      "When I am king\n",
      "You will be first against the wall\n",
      "With your opinion\n",
      "Which is of no consequence at all\n",
      "What's that? (I may be paranoid, but no android)\n",
      "What's that? (I may be paranoid, but no android)\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La, la\n",
      "Ambition makes you look pretty ugly\n",
      "Kicking, squealing, Gucci little piggy\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la\n",
      "You {do}{n't} remember, you {do}{n't} remember\n",
      "Why {do}{n't} you remember my name?\n",
      "Off with his head, man, off with his head, man\n",
      "Why {do}{n't} you remember my name?\n",
      "I guess he does\n",
      "Ah, oh, oh, oh\n",
      "Oh, oh, oh, oh\n",
      "Oh, oh\n",
      "Oh, oh\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From a great height\n",
      "From a great height, height\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From a great height\n",
      "From a great height, height\n",
      "that's it, sir, you're leaving\n",
      "The crackle of pigskin (rain down)\n",
      "(Come on rain down) the dust and the screaming\n",
      "The yuppies networking\n",
      "The panic, the vomit (from a great height)\n",
      "The panic, the vomit (from a great height)\n",
      "God loves his children\n",
      "God loves his children, yeah\n"
     ]
    }
   ],
   "source": [
    "ex22 = r'n\\'t|\\w+' \n",
    "ex22_me = r'don\\'t'\n",
    "ex22_me1 = r'n\\'t|do(?=n\\'t)'\n",
    "nltk.re_show(ex22_me1, paranoid_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.481838Z",
     "start_time": "2024-04-20T12:19:04.479857Z"
    }
   },
   "id": "f4b8f5697f71948c",
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 24. Try to write code to convert text into hAck3r, using regular expressions and substitution, where e â 3, i â 1, o â 0, l â |, s â 5, . â 5w33t!, ate â 8. Normalize the text to lowercase before converting it. Add more substitutions of your own. Now try to map s to two different values: $ for word-initial s, and 5 for word-internal s."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4dfd8236cbc83a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "paranoid_full_ex24 = paranoid_full.lower() \n",
    "\n",
    "# idk how to do it in a more sophisticated way\n",
    "paranoid_full_ex24 = re.sub(r'e', '3', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'i', '1', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'o', '1', paranoid_full_ex24)   \n",
    "paranoid_full_ex24 = re.sub(r'l', '|', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'\\.', '5w33t!', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'ate', '8', paranoid_full_ex24)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.484664Z",
     "start_time": "2024-04-20T12:19:04.482500Z"
    }
   },
   "id": "4185307123764633",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plea5e could you $top the noi5e?\n",
      "i'm tryna get $ome re5t\n",
      "from all the unborn chicken\n",
      "voice5 in my head\n",
      "what's that? (i may be paranoid, but not an android)\n",
      "what's that? (i may be paranoid, but not an android)\n",
      "when i am king\n",
      "you will be fir5t again5t the wall\n",
      "with your opinion\n",
      "which i5 of no con5equence at all\n",
      "what's that? (i may be paranoid, but no android)\n",
      "what's that? (i may be paranoid, but no android)\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la, la\n",
      "ambition make5 you look pretty ugly\n",
      "kicking, $quealing, gucci little piggy\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la\n",
      "you don't remember, you don't remember\n",
      "why don't you remember my name?\n",
      "off with hi5 head, man, off with hi5 head, man\n",
      "why don't you remember my name?\n",
      "i gue55 he doe5\n",
      "ah, oh, oh, oh\n",
      "oh, oh, oh, oh\n",
      "oh, oh\n",
      "oh, oh\n",
      "rain down, rain down\n",
      "come on, rain down on me\n",
      "from a great height\n",
      "from a great height, height\n",
      "rain down, rain down\n",
      "come on, rain down on me\n",
      "from a great height\n",
      "from a great height, height\n",
      "that's it, $ir, you're leaving\n",
      "the crackle of pig5kin (rain down)\n",
      "(come on rain down) the du5t and the $creaming\n",
      "the yuppie5 networking\n",
      "the panic, the vomit (from a great height)\n",
      "the panic, the vomit (from a great height)\n",
      "god love5 hi5 children\n",
      "god love5 hi5 children, yeah\n"
     ]
    }
   ],
   "source": [
    "paranoid_full_ex24 = paranoid_full.lower() \n",
    "paranoid_full_ex24 = re.sub(r'\\ss', ' $', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'(?<!\\b)s', '5', paranoid_full_ex24)\n",
    "print(paranoid_full_ex24)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.487624Z",
     "start_time": "2024-04-20T12:19:04.485374Z"
    }
   },
   "id": "6ff454c008a294",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p|3a53 c1u|d y1u $t1p th3 n1153?\n",
      "1'm tryna g3t $1m3 r35t\n",
      "fr1m a|| th3 unb1rn ch1ck3n\n",
      "v11c35 1n my h3ad\n",
      "what'5 that? (1 may b3 paran11d, but n1t an andr11d)\n",
      "what'5 that? (1 may b3 paran11d, but n1t an andr11d)\n",
      "wh3n 1 am k1ng\n",
      "y1u w1|| b3 f1r5t aga1n5t th3 wa||\n",
      "w1th y1ur 1p1n11n\n",
      "wh1ch 15 1f n1 c1n53qu3nc3 at a||\n",
      "what'5 that? (1 may b3 paran11d, but n1 andr11d)\n",
      "what'5 that? (1 may b3 paran11d, but n1 andr11d)\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a, |a\n",
      "amb1t11n mak35 y1u |11k pr3tty ug|y\n",
      "k1ck1ng, $qu3a|1ng, gucc1 |1tt|3 p1ggy\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a\n",
      "y1u d1n't r3m3mb3r, y1u d1n't r3m3mb3r\n",
      "why d1n't y1u r3m3mb3r my nam3?\n",
      "1ff w1th h15 h3ad, man, 1ff w1th h15 h3ad, man\n",
      "why d1n't y1u r3m3mb3r my nam3?\n",
      "1 gu355 h3 d135\n",
      "ah, 1h, 1h, 1h\n",
      "1h, 1h, 1h, 1h\n",
      "1h, 1h\n",
      "1h, 1h\n",
      "ra1n d1wn, ra1n d1wn\n",
      "c1m3 1n, ra1n d1wn 1n m3\n",
      "fr1m a gr3at h31ght\n",
      "fr1m a gr3at h31ght, h31ght\n",
      "ra1n d1wn, ra1n d1wn\n",
      "c1m3 1n, ra1n d1wn 1n m3\n",
      "fr1m a gr3at h31ght\n",
      "fr1m a gr3at h31ght, h31ght\n",
      "that'5 1t, $1r, y1u'r3 |3av1ng\n",
      "th3 crack|3 1f p1g5k1n (ra1n d1wn)\n",
      "(c1m3 1n ra1n d1wn) th3 du5t and th3 $cr3am1ng\n",
      "th3 yupp135 n3tw1rk1ng\n",
      "th3 pan1c, th3 v1m1t (fr1m a gr3at h31ght)\n",
      "th3 pan1c, th3 v1m1t (fr1m a gr3at h31ght)\n",
      "g1d |1v35 h15 ch1|dr3n\n",
      "g1d |1v35 h15 ch1|dr3n, y3ah\n"
     ]
    }
   ],
   "source": [
    "# from ChatGPT > I don't know '|'.join, re.escape and re.compile and don't remember how lambda works :( \n",
    "# Define the replacements\n",
    "replacements = {\n",
    "    'e': '3',\n",
    "    'i': '1',\n",
    "    'o': '1',\n",
    "    'l': '|',\n",
    "    's': '5',\n",
    "    '.': '5w33t!',\n",
    "    'ate': '8'\n",
    "}\n",
    "\n",
    "# Define a function to perform the replacements\n",
    "def replace_chars(text, replacements):\n",
    "    pattern = re.compile('|'.join(re.escape(key) for key in replacements.keys()))\n",
    "    return pattern.sub(lambda x: replacements[x.group()], text)\n",
    "\n",
    "# Apply the replacements\n",
    "paranoid_full_ex24_gpt = replace_chars(paranoid_full_ex24, replacements)\n",
    "print(paranoid_full_ex24_gpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.490852Z",
     "start_time": "2024-04-20T12:19:04.488288Z"
    }
   },
   "id": "b609f3561a9c1a0",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T12:19:04.492711Z",
     "start_time": "2024-04-20T12:19:04.491512Z"
    }
   },
   "id": "b9c7c80e245703e0",
   "execution_count": 179
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
