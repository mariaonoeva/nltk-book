{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 3: Processing Raw Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c2eb58aa5243b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from urllib import request"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:52.675100Z",
     "start_time": "2024-04-01T13:44:52.669998Z"
    }
   },
   "id": "2e1af2ea9c073a19",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 1176812 ï»¿The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\r\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.gutenberg.org/files/2554/2554-0.txt'\n",
    "response = request.urlopen(url) \n",
    "raw = response.read().decode('utf-8')\n",
    "print(type(raw), len(raw), raw[:75])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:56.009479Z",
     "start_time": "2024-04-01T13:44:52.738385Z"
    }
   },
   "id": "417a11f454819a90",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 257058 ['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "print(type(tokens), len(tokens), tokens[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:56.717352Z",
     "start_time": "2024-04-01T13:44:56.013419Z"
    }
   },
   "id": "e33f436b06458252",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insight', 'impresses', 'us', 'as', 'wisdom', '...', 'that', 'wisdom', 'of', 'the', 'heart', 'which', 'we', 'seek', 'that', 'we', 'may', 'learn', 'from', 'it', 'how', 'to', 'live', '.', 'All', 'his', 'other', 'gifts', 'came', 'to', 'him', 'from', 'nature', ',', 'this', 'he', 'won', 'for']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Project Gutenberg; Ilya\n",
      "Petrovitch; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(text[1024:1062])\n",
    "print(text.collocations())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:56.990622Z",
     "start_time": "2024-04-01T13:44:56.718244Z"
    }
   },
   "id": "60f3508389663891",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 37306\n",
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\n"
     ]
    }
   ],
   "source": [
    "url1 = 'http://news.bbc.co.uk/2/hi/health/2284783.stm'\n",
    "html = request.urlopen(url1).read().decode('utf8')\n",
    "print(type(html), len(html))\n",
    "print(html[:60])\n",
    "#print(html)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.226777Z",
     "start_time": "2024-04-01T13:44:56.992095Z"
    }
   },
   "id": "4cb667ae56daf57f",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "24338\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "raw1 = BeautifulSoup(html, 'html.parser').get_text() \n",
    "tokens_html = word_tokenize(raw1)\n",
    "text_html = nltk.Text(tokens_html)\n",
    "text_html.concordance('gene')\n",
    "#print(tokens_html)\n",
    "\n",
    "print(html.find('of the'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.257082Z",
     "start_time": "2024-04-01T13:44:57.228560Z"
    }
   },
   "id": "8583cd034c0699ad",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hp_1 = open('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')\n",
    "raw_HP = hp_1.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.261579Z",
     "start_time": "2024-04-01T13:44:57.258004Z"
    }
   },
   "id": "e47be2abe3215826",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.268697Z",
     "start_time": "2024-04-01T13:44:57.262642Z"
    }
   },
   "id": "9f94c64b7773b66",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's\n",
      "the\n",
      "worst\n",
      "case\n",
      "scenario\n",
      "lullaby\n",
      "I t ' s   t h e   w o r s t   c a s e   s c e n a r i o   l u l l a b y "
     ]
    }
   ],
   "source": [
    "my_sentence = 'It\\'s the worst case scenario lullaby'\n",
    "for i in my_sentence.split(' '):\n",
    "    print(i)\n",
    "    \n",
    "for char in my_sentence: \n",
    "    print(char, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.275119Z",
     "start_time": "2024-04-01T13:44:57.271711Z"
    }
   },
   "id": "7b8288161b316ba1",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aba', 'abac', 'abaca', 'abaff', 'abb', 'abed', 'acca', 'accede', 'ace', 'ad', 'adad', 'add', 'adda', 'added', 'ade', 'adead', 'ae', 'aface', 'affa', 'ajaja', 'b', 'ba', 'baa', 'baba', 'babe', 'bac', 'bacaba', 'bacca', 'baccae', 'bad', 'bade', 'bae', 'baff', 'bajada', 'be', 'bead', 'beaded', 'bebed', 'bed', 'bedad', 'bedded', 'bedead', 'bedeaf', 'bee', 'beef', 'bejade', 'c', 'ca', 'cab', 'caba', 'cabda', 'cad', 'cade', 'caeca', 'caffa', 'ce', 'cede', 'cee', 'd', 'da', 'dab', 'dabb', 'dabba', 'dace', 'dad', 'dada', 'dade', 'dae', 'daff', 'de', 'dead', 'deaf', 'deb', 'decad', 'decade', 'dee', 'deed', 'deedeed', 'deface', 'e', 'ea', 'ebb', 'ecad', 'edea', 'efface', 'f', 'fa', 'facade', 'face', 'faced', 'fad', 'fade', 'faded', 'fae', 'faff', 'fe', 'fed', 'fee', 'feed', 'j', 'jab', 'jabbed', 'jade', 'jaded', 'jed', 'jeff']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'j', 'k', 'l', 'm', 'n', 'o']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']\n"
     ]
    }
   ],
   "source": [
    "word_list = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "# print([w for w in word_list if re.search('ed$', w)])\n",
    "# print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "# print([w for w in word_list if re.search('..j..t..', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]+$', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj]+$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-o]$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.546876Z",
     "start_time": "2024-04-01T13:44:57.275814Z"
    }
   },
   "id": "9403ab0726ddab0a",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "print([w for w in word_list if re.search(r'^..j..t..$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.677256Z",
     "start_time": "2024-04-01T13:44:57.548972Z"
    }
   },
   "id": "6003f991e5d91e7d",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\\n\n",
      "\n",
      "\\b\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/26318287/what-does-r-mean-before-a-regex-pattern\n",
    "print('\\n') # Prints a newline character\n",
    "print(r'\\n') # Escape sequence is not processed\n",
    "print('\\b') # Prints a backspace character\n",
    "print(r'\\b') # Escape sequence is not processed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.680228Z",
     "start_time": "2024-04-01T13:44:57.678039Z"
    }
   },
   "id": "63eb5733d21fbc30",
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": [
    "I guess I got it. So by prefixing with 'r' we kinda say to Python not to read into that but simply to pass a combination to re library, ok!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6b535d84843aa1b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009, 12, 31]\n"
     ]
    }
   ],
   "source": [
    "print([int(n) for n in re.findall(r'[0-9]{2,}', '2009-12-31')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.683274Z",
     "start_time": "2024-04-01T13:44:57.680802Z"
    }
   },
   "id": "f902aa2546d6c412",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P}lease could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{F}rom all the unborn chicken\n",
      "{V}oices in my head\n"
     ]
    }
   ],
   "source": [
    "paranoid = \"\"\"Please could you stop the noise?\n",
    "I'm tryna get some rest\n",
    "From all the unborn chicken\n",
    "Voices in my head\"\"\"\n",
    "pattern = r'^[A-Z]'\n",
    "pattern1 = r'\\?$'\n",
    "pattern2 = r'es$' # finds nothing because it thinks of the line as the whole string and no line ends with 'es', so in order it to work I have to tokenize it first \n",
    "\n",
    "nltk.re_show(pattern, paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:57.686576Z",
     "start_time": "2024-04-01T13:44:57.683947Z"
    }
   },
   "id": "98a5c5477f6af1e",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n",
      "as accurately as possible; as well as the; as faithfully as possible;\n",
      "as much as what; as neat as a; as simple as you; as well as other; as\n",
      "well as other; as involved as determining; as well as other; as\n",
      "important as another; as accurately as possible; as accurate as any;\n",
      "as much as any; as different as a; as Orphic as that; as coppery as\n",
      "Delawares; as good as another; as large as small; as well as ease; as\n",
      "well as their; as well as possible; as straight as possible; as well\n",
      "as nailed; as smoothly as the; as soon as a; as well as injuries; as\n",
      "well as many; as well as reason; as well as in; as well as of; as well\n",
      "as a; as well as summer; as well as providing; as important as\n",
      "cooling; as evenly as it; as much as shading; as well as some; as well\n",
      "as subsoil; as high as possible; as well as many; as general as\n",
      "electrical; as long as the; as well as the; as much as was; as well as\n",
      "set; as well as by; as high as 15; as well as aid; as much as\n",
      "possible; as well as personalities; as low as a; as well as the; as\n",
      "much as glass; as popular as renting; as expensive as most; as well as\n",
      "relative; as well as by; as well as the; as far as possible; as far as\n",
      "radiation; as well as theoretical; as well as nuclear; as small as\n",
      "possible; as well as soap; as effective as the; as much as\n",
      "approximately; as well as information; as little as one; as much as\n",
      "an; as low as Af; as long as the; as far as possible; as well as\n",
      "their; as well as Hand; as well as all; as well as fractionation; as\n",
      "potent as the; as well as fever; as large as 3; as well as varying; as\n",
      "well as the; as long as 2; as far as emotional; as well as the; as\n",
      "well as regarding; as well as enthusiasm; as well as by; as well as\n",
      "her; as well as a; as old as social; as well as the; as well as the;\n",
      "as well as in; as much as they; as much as possible; as well as the;\n",
      "as well as some; as simple as one; as well as the; as well as in; as\n",
      "definable as possible; as long as they; as well as their; as well as\n",
      "forecasting; as soon as possible; as inevitable as anything; as well\n",
      "as for; as well as for; as nebulous as the; as awkward as the; as well\n",
      "as the; as well as by; as well as those; as well as the; as well as\n",
      "an; as well as with; as well as the; as well as moral; as much as\n",
      "their; as well as that; as likely as not; as well as upon; as well as\n",
      "on; as well as upon; as long as all; as far as one; as long as the; as\n",
      "empty as the; as well as the; as well as the; as soon as they; as well\n",
      "as office; as speedily as possible; as well as of; as well as start;\n",
      "as well as behind; as much as for; as effectively as they; as\n",
      "important as it; as nearly as feasible; as well as form; as well as\n",
      "aesthetic; as well as ethical; as well as Impressionism; as well as\n",
      "the; as broad as the; as much as he; as arresting as a; as odd as the;\n",
      "as well as the; as soon as possible; as long as it; as impassive as\n",
      "Persian; as long as those; as importantly as his; as well as\n",
      "providing; as well as the; as well as vertically; as well as new; as\n",
      "well as certain; as well as the; as close as possible; as far as\n",
      "obtainable; as well as the; as important as the; as long as the; as\n",
      "satisfactory as those\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown \n",
    "hobbies_learned = nltk.Text(brown.words(categories = ['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r'<\\w*> <and> <other> <\\w*s>')\n",
    "hobbies_learned.findall(r'<as> <\\w*> <as> <\\w*>')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.159733Z",
     "start_time": "2024-04-01T13:44:57.687338Z"
    }
   },
   "id": "2b4e98daacedbb63",
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercises \n",
    "#### 1. Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95502eba563befe0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colourless\n"
     ]
    }
   ],
   "source": [
    "s = 'colorless' \n",
    "print(s[:4] + 'u' + s[4:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.162672Z",
     "start_time": "2024-04-01T13:44:58.160472Z"
    }
   },
   "id": "76a23c7b827e1613",
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9281da907ef951ce"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dish', 'run', 'nation', 'do', 'heat']\n"
     ]
    }
   ],
   "source": [
    "ex2_words = [w for w in 'dish-es, run-ning, nation-ality, un-do, pre-heat'.split(', ')]\n",
    "ex2_noaff = [ex2_words[0][:-3], ex2_words[1][:-5], ex2_words[2][:-6], ex2_words[3][-2:], ex2_words[4][-4:]]\n",
    "print(ex2_noaff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.166420Z",
     "start_time": "2024-04-01T13:44:58.163586Z"
    }
   },
   "id": "3f1bab5ab0e0ad45",
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string? \n",
    "I don't think so. I cannot use negative numbers as they remove chars and the lowest possible is then 0 which is the first char.\n",
    " \n",
    "Okay, I see it now. I thought about slicing but not about indexing. So it's possible to raise the error then. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232e2c1ec1fc3f3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "o\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "s = \"hello\"\n",
    "print(s[-6:])  # This will print 'hello'\n",
    "print(s[-100:])  # Still prints 'hello', as slicing is more forgiving\n",
    "print(s[-1])  # This will print 'o'\n",
    "print(s[-5])  # This will print 'h'\n",
    "# Accessing beyond the start (too far to the left)\n",
    "#print(s[-6])  # This will raise an IndexError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.169128Z",
     "start_time": "2024-04-01T13:44:58.167099Z"
    }
   },
   "id": "c1e07d4ad2481ab3",
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc4ba639f33690e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pes ol o tptenie\n",
      "' rn e oers\n",
      "rmalteubr hce\n",
      "ocsi yha\n",
      "lo \n"
     ]
    }
   ],
   "source": [
    "print(paranoid[::2])\n",
    "print(paranoid[10:5:-2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.172416Z",
     "start_time": "2024-04-01T13:44:58.169885Z"
    }
   },
   "id": "e5158f4a4b4754e1",
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result.\n",
    "It reverses a string, but why can it be reasonable? Perhaps if some text is reversed, it can reverse it back. Or to print some text so it's readable in mirrors. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "832f6cb4e71a2fad"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daeh ym ni secioV\n",
      "nekcihc nrobnu eht lla morF\n",
      "tser emos teg anyrt m'I\n",
      "?esion eht pots uoy dluoc esaelP\n",
      "Please could you stop the noise?\n",
      "I'm tryna get some rest\n",
      "From all the unborn chicken\n",
      "Voices in my head\n"
     ]
    }
   ],
   "source": [
    "print(paranoid[::-1])\n",
    "print(paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.174826Z",
     "start_time": "2024-04-01T13:44:58.173147Z"
    }
   },
   "id": "4d0c7290d472711",
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Describe the class of strings matched by the following regular expressions. \n",
    "1. ```[a-zA-Z]+```: '+' means one or more of previous item, in this case one or more of any letter, case doesn't matter ('cat', 'so') > any word \n",
    "2. ```[A-Z][a-z]*```: here case matters, so first it should be an upper one then zero or more of any lower case ('D', 'Dog') > any upper case word \n",
    "3. ```p[aeiou]{,2}t```: a sequence should start with 'p' and end with 't', then between there should be at most 2 vowels > too much output, replacing it with ```^p[aeiou]{,2}t$``` ('put', 'poet') \n",
    "4. ```\\d+(\\.\\d+)?```: one or more digits and zero or one ('?') of digits after the decimal point\n",
    "5. ```([^aeiou][aeiou][^aeiou])*```: zero or more instances of a chunk that doesn't start with a vowel then has one vowel and doen't end with the vowel, so its CVC* combinations (??)  -- huh? \n",
    "6. ```\\w+|[^\\w\\s]+```: any alphanumeric char OR something that doesn't start with any alphanumeric char and a white space -- anything that is not a space?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6166b84c0ec21f4e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Please} {could} {you} {stop} {the} {noise}?\n",
      "{I}'{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n",
      "{Please} could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{From} all the unborn chicken\n",
      "{Voices} in my head\n",
      "['pat', 'paut', 'peat', 'pet', 'piet', 'pit', 'poet', 'poot', 'pot', 'pout', 'put']\n",
      "[]\n",
      "{}P{}l{}e{}a{se }{}c{}o{}u{}l{}d{} {}y{}o{}u{} {}s{top}{} {}t{he }{}n{}o{}i{se?}{}\n",
      "{}I{}'{}m{} {}t{}r{}y{na get}{} {som}{}e{} {res}{}t{}\n",
      "{}F{rom al}{}l{} {}t{he }{}u{}n{bor}{}n{} {}c{hicken}{}\n",
      "{}V{}o{}i{ces in}{} {}m{}y{} {}h{}e{}a{}d{}\n",
      "{Please} {could} {you} {stop} {the} {noise}{?}\n",
      "{I}{'}{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r'[a-zA-Z]+', paranoid)\n",
    "nltk.re_show(r'[A-Z][a-z]*', paranoid)\n",
    "print([w for w in word_list if re.search(r'^p[aeiou]{,2}t$', w)])\n",
    "print([w for w in word_list if re.search(r'\\d+(\\.\\d+)?', w)])\n",
    "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', paranoid)\n",
    "nltk.re_show(r'\\w+|[^\\w\\s]+', paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.332468Z",
     "start_time": "2024-04-01T13:44:58.175623Z"
    }
   },
   "id": "c2f2afbe41377ed2",
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:44:58.334459Z",
     "start_time": "2024-04-01T13:44:58.333102Z"
    }
   },
   "id": "e25a45ab3d5bfcc5",
   "execution_count": 104
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
