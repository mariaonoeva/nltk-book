{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 3: Processing Raw Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c2eb58aa5243b6"
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from urllib import request"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:16.076384Z",
     "start_time": "2025-02-25T09:37:16.071397Z"
    }
   },
   "id": "2e1af2ea9c073a19",
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": [
    "url = 'http://www.gutenberg.org/files/2554/2554-0.txt'\n",
    "response = request.urlopen(url) \n",
    "raw = response.read().decode('utf-8')\n",
    "print(type(raw), len(raw), raw[:75])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:17.835703Z",
     "start_time": "2025-02-25T09:37:16.488757Z"
    }
   },
   "id": "417a11f454819a90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 1135214 *** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CRIME AND PUNISHMENT\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": [
    "tokens = word_tokenize(raw)\n",
    "print(type(tokens), len(tokens), tokens[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:18.886508Z",
     "start_time": "2025-02-25T09:37:17.840780Z"
    }
   },
   "id": "e33f436b06458252",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 253688 ['*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', '2554']\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(text[1024:1062])\n",
    "print(text.collocations())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.207631Z",
     "start_time": "2025-02-25T09:37:18.888622Z"
    }
   },
   "id": "60f3508389663891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kitchen', ',', 'the', 'door', 'of', 'which', 'invariably', 'stood', 'open', '.', 'And', 'each', 'time', 'he', 'passed', ',', 'the', 'young', 'man', 'had', 'a', 'sick', ',', 'frightened', 'feeling', ',', 'which', 'made', 'him', 'scowl', 'and', 'feel', 'ashamed', '.', 'He', 'was', 'hopelessly', 'in']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Porfiry Petrovitch; Amalia Ivanovna; great deal; young man;\n",
      "Nikodim Fomitch; Ilya Petrovitch; Andrey Semyonovitch; Hay Market;\n",
      "Dmitri Prokofitch; Good heavens; police station; head clerk\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "url1 = 'http://news.bbc.co.uk/2/hi/health/2284783.stm'\n",
    "html = request.urlopen(url1).read().decode('utf8')\n",
    "print(type(html), len(html))\n",
    "print(html[:60])\n",
    "#print(html)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.377715Z",
     "start_time": "2025-02-25T09:37:19.209809Z"
    }
   },
   "id": "4cb667ae56daf57f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 37306\n",
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup \n",
    "raw1 = BeautifulSoup(html, 'html.parser').get_text() \n",
    "tokens_html = word_tokenize(raw1)\n",
    "text_html = nltk.Text(tokens_html)\n",
    "text_html.concordance('gene')\n",
    "#print(tokens_html)\n",
    "\n",
    "print(html.find('of the'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.403748Z",
     "start_time": "2025-02-25T09:37:19.378859Z"
    }
   },
   "id": "8583cd034c0699ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "24338\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "hp_1 = open('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')\n",
    "raw_HP = hp_1.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.407927Z",
     "start_time": "2025-02-25T09:37:19.404668Z"
    }
   },
   "id": "e47be2abe3215826",
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.411805Z",
     "start_time": "2025-02-25T09:37:19.408973Z"
    }
   },
   "id": "9f94c64b7773b66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": [
    "my_sentence = 'It\\'s the worst case scenario lullaby'\n",
    "for i in my_sentence.split(' '):\n",
    "    print(i)\n",
    "    \n",
    "for char in my_sentence: \n",
    "    print(char, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.415046Z",
     "start_time": "2025-02-25T09:37:19.412539Z"
    }
   },
   "id": "7b8288161b316ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's\n",
      "the\n",
      "worst\n",
      "case\n",
      "scenario\n",
      "lullaby\n",
      "I t ' s   t h e   w o r s t   c a s e   s c e n a r i o   l u l l a b y "
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "source": [
    "word_list = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "# print([w for w in word_list if re.search('ed$', w)])\n",
    "# print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "# print([w for w in word_list if re.search('..j..t..', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]+$', w)])\n",
    "# print([w for w in word_list if re.search('^[g-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj]+$', w)])\n",
    "print([w for w in word_list if re.search('^[a-fj-o]$', w)])\n",
    "print([w for w in word_list if re.search('^[a-o]$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.695333Z",
     "start_time": "2025-02-25T09:37:19.416001Z"
    }
   },
   "id": "9403ab0726ddab0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aba', 'abac', 'abaca', 'abaff', 'abb', 'abed', 'acca', 'accede', 'ace', 'ad', 'adad', 'add', 'adda', 'added', 'ade', 'adead', 'ae', 'aface', 'affa', 'ajaja', 'b', 'ba', 'baa', 'baba', 'babe', 'bac', 'bacaba', 'bacca', 'baccae', 'bad', 'bade', 'bae', 'baff', 'bajada', 'be', 'bead', 'beaded', 'bebed', 'bed', 'bedad', 'bedded', 'bedead', 'bedeaf', 'bee', 'beef', 'bejade', 'c', 'ca', 'cab', 'caba', 'cabda', 'cad', 'cade', 'caeca', 'caffa', 'ce', 'cede', 'cee', 'd', 'da', 'dab', 'dabb', 'dabba', 'dace', 'dad', 'dada', 'dade', 'dae', 'daff', 'de', 'dead', 'deaf', 'deb', 'decad', 'decade', 'dee', 'deed', 'deedeed', 'deface', 'e', 'ea', 'ebb', 'ecad', 'edea', 'efface', 'f', 'fa', 'facade', 'face', 'faced', 'fad', 'fade', 'faded', 'fae', 'faff', 'fe', 'fed', 'fee', 'feed', 'j', 'jab', 'jabbed', 'jade', 'jaded', 'jed', 'jeff']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'j', 'k', 'l', 'm', 'n', 'o']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "print([w for w in word_list if re.search('^..j..t..$', w)])\n",
    "print([w for w in word_list if re.search(r'^..j..t..$', w)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.830614Z",
     "start_time": "2025-02-25T09:37:19.697701Z"
    }
   },
   "id": "6003f991e5d91e7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "# https://stackoverflow.com/questions/26318287/what-does-r-mean-before-a-regex-pattern\n",
    "print('\\n') # Prints a newline character\n",
    "print(r'\\n') # Escape sequence is not processed\n",
    "print('\\b') # Prints a backspace character\n",
    "print(r'\\b') # Escape sequence is not processed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.833294Z",
     "start_time": "2025-02-25T09:37:19.831354Z"
    }
   },
   "id": "63eb5733d21fbc30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\\n\n",
      "\n",
      "\\b\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "I guess I got it. So by prefixing with 'r' we kinda say to Python not to read into that but simply to pass a combination to re library, ok!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6b535d84843aa1b"
  },
  {
   "cell_type": "code",
   "source": [
    "print([int(n) for n in re.findall(r'[0-9]{2,}', '2009-12-31')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.837502Z",
     "start_time": "2025-02-25T09:37:19.834060Z"
    }
   },
   "id": "f902aa2546d6c412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009, 12, 31]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "paranoid = \"\"\"Please could you stop the noise?\n",
    "I'm tryna get some rest\n",
    "From all the unborn chicken\n",
    "Voices in my head\"\"\"\n",
    "pattern = r'^[A-Z]'\n",
    "pattern1 = r'\\?$'\n",
    "pattern2 = r'es$' # finds nothing because it thinks of the line as the whole string and no line ends with 'es', so in order it to work I have to tokenize it first \n",
    "\n",
    "nltk.re_show(pattern, paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:19.840365Z",
     "start_time": "2025-02-25T09:37:19.838167Z"
    }
   },
   "id": "98a5c5477f6af1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P}lease could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{F}rom all the unborn chicken\n",
      "{V}oices in my head\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.corpus import brown \n",
    "hobbies_learned = nltk.Text(brown.words(categories = ['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r'<\\w*> <and> <other> <\\w*s>')\n",
    "hobbies_learned.findall(r'<as> <\\w*> <as> <\\w*>')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.400951Z",
     "start_time": "2025-02-25T09:37:19.841184Z"
    }
   },
   "id": "2b4e98daacedbb63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n",
      "as accurately as possible; as well as the; as faithfully as possible;\n",
      "as much as what; as neat as a; as simple as you; as well as other; as\n",
      "well as other; as involved as determining; as well as other; as\n",
      "important as another; as accurately as possible; as accurate as any;\n",
      "as much as any; as different as a; as Orphic as that; as coppery as\n",
      "Delawares; as good as another; as large as small; as well as ease; as\n",
      "well as their; as well as possible; as straight as possible; as well\n",
      "as nailed; as smoothly as the; as soon as a; as well as injuries; as\n",
      "well as many; as well as reason; as well as in; as well as of; as well\n",
      "as a; as well as summer; as well as providing; as important as\n",
      "cooling; as evenly as it; as much as shading; as well as some; as well\n",
      "as subsoil; as high as possible; as well as many; as general as\n",
      "electrical; as long as the; as well as the; as much as was; as well as\n",
      "set; as well as by; as high as 15; as well as aid; as much as\n",
      "possible; as well as personalities; as low as a; as well as the; as\n",
      "much as glass; as popular as renting; as expensive as most; as well as\n",
      "relative; as well as by; as well as the; as far as possible; as far as\n",
      "radiation; as well as theoretical; as well as nuclear; as small as\n",
      "possible; as well as soap; as effective as the; as much as\n",
      "approximately; as well as information; as little as one; as much as\n",
      "an; as low as Af; as long as the; as far as possible; as well as\n",
      "their; as well as Hand; as well as all; as well as fractionation; as\n",
      "potent as the; as well as fever; as large as 3; as well as varying; as\n",
      "well as the; as long as 2; as far as emotional; as well as the; as\n",
      "well as regarding; as well as enthusiasm; as well as by; as well as\n",
      "her; as well as a; as old as social; as well as the; as well as the;\n",
      "as well as in; as much as they; as much as possible; as well as the;\n",
      "as well as some; as simple as one; as well as the; as well as in; as\n",
      "definable as possible; as long as they; as well as their; as well as\n",
      "forecasting; as soon as possible; as inevitable as anything; as well\n",
      "as for; as well as for; as nebulous as the; as awkward as the; as well\n",
      "as the; as well as by; as well as those; as well as the; as well as\n",
      "an; as well as with; as well as the; as well as moral; as much as\n",
      "their; as well as that; as likely as not; as well as upon; as well as\n",
      "on; as well as upon; as long as all; as far as one; as long as the; as\n",
      "empty as the; as well as the; as well as the; as soon as they; as well\n",
      "as office; as speedily as possible; as well as of; as well as start;\n",
      "as well as behind; as much as for; as effectively as they; as\n",
      "important as it; as nearly as feasible; as well as form; as well as\n",
      "aesthetic; as well as ethical; as well as Impressionism; as well as\n",
      "the; as broad as the; as much as he; as arresting as a; as odd as the;\n",
      "as well as the; as soon as possible; as long as it; as impassive as\n",
      "Persian; as long as those; as importantly as his; as well as\n",
      "providing; as well as the; as well as vertically; as well as new; as\n",
      "well as certain; as well as the; as close as possible; as far as\n",
      "obtainable; as well as the; as important as the; as long as the; as\n",
      "satisfactory as those\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercises \n",
    "#### 1. Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95502eba563befe0"
  },
  {
   "cell_type": "code",
   "source": [
    "s = 'colorless' \n",
    "print(s[:4] + 'u' + s[4:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.403952Z",
     "start_time": "2025-02-25T09:37:20.401679Z"
    }
   },
   "id": "76a23c7b827e1613",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colourless\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9281da907ef951ce"
  },
  {
   "cell_type": "code",
   "source": [
    "ex2_words = [w for w in 'dish-es, run-ning, nation-ality, un-do, pre-heat'.split(', ')]\n",
    "ex2_noaff = [ex2_words[0][:-3], ex2_words[1][:-5], ex2_words[2][:-6], ex2_words[3][-2:], ex2_words[4][-4:]]\n",
    "print(ex2_noaff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.407417Z",
     "start_time": "2025-02-25T09:37:20.404689Z"
    }
   },
   "id": "3f1bab5ab0e0ad45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dish', 'run', 'nation', 'do', 'heat']\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string? \n",
    "I don't think so. I cannot use negative numbers as they remove chars and the lowest possible is then 0 which is the first char.\n",
    " \n",
    "Okay, I see it now. I thought about slicing but not about indexing. So it's possible to raise the error then. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232e2c1ec1fc3f3"
  },
  {
   "cell_type": "code",
   "source": [
    "s = \"hello\"\n",
    "print(s[-6:])  # This will print 'hello'\n",
    "print(s[-100:])  # Still prints 'hello', as slicing is more forgiving\n",
    "print(s[-1])  # This will print 'o'\n",
    "print(s[-5])  # This will print 'h'\n",
    "# Accessing beyond the start (too far to the left)\n",
    "#print(s[-6])  # This will raise an IndexError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.410545Z",
     "start_time": "2025-02-25T09:37:20.408232Z"
    }
   },
   "id": "c1e07d4ad2481ab3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "o\n",
      "h\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc4ba639f33690e"
  },
  {
   "cell_type": "code",
   "source": [
    "print(paranoid[::2])\n",
    "print(paranoid[10:5:-2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.414588Z",
     "start_time": "2025-02-25T09:37:20.411441Z"
    }
   },
   "id": "e5158f4a4b4754e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pes ol o tptenie\n",
      "' rn e oers\n",
      "rmalteubr hce\n",
      "ocsi yha\n",
      "lo \n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result.\n",
    "It reverses a string, but why can it be reasonable? Perhaps if some text is reversed, it can reverse it back. Or to print some text so it's readable in mirrors. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "832f6cb4e71a2fad"
  },
  {
   "cell_type": "code",
   "source": [
    "print(paranoid[::-1])\n",
    "print(paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.417732Z",
     "start_time": "2025-02-25T09:37:20.415511Z"
    }
   },
   "id": "4d0c7290d472711",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daeh ym ni secioV\n",
      "nekcihc nrobnu eht lla morF\n",
      "tser emos teg anyrt m'I\n",
      "?esion eht pots uoy dluoc esaelP\n",
      "Please could you stop the noise?\n",
      "I'm tryna get some rest\n",
      "From all the unborn chicken\n",
      "Voices in my head\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Describe the class of strings matched by the following regular expressions. \n",
    "1. ```[a-zA-Z]+```: '+' means one or more of previous item, in this case one or more of any letter, case doesn't matter ('cat', 'so') > any word \n",
    "2. ```[A-Z][a-z]*```: here case matters, so first it should be an upper one then zero or more of any lower case ('D', 'Dog') > any upper case word \n",
    "3. ```p[aeiou]{,2}t```: a sequence should start with 'p' and end with 't', then between there should be at most 2 vowels > too much output, replacing it with ```^p[aeiou]{,2}t$``` ('put', 'poet') \n",
    "4. ```\\d+(\\.\\d+)?```: one or more digits and zero or one ('?') of digits after the decimal point\n",
    "5. ```([^aeiou][aeiou][^aeiou])*```: zero or more instances of a chunk that doesn't start with a vowel then has one vowel and doen't end with the vowel, so its CVC* combinations (??)  -- huh? \n",
    "6. ```\\w+|[^\\w\\s]+```: any alphanumeric char OR something that doesn't start with any alphanumeric char and a white space -- anything that is not a space?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6166b84c0ec21f4e"
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.re_show(r'[a-zA-Z]+', paranoid)\n",
    "nltk.re_show(r'[A-Z][a-z]*', paranoid)\n",
    "print([w for w in word_list if re.search(r'^p[aeiou]{,2}t$', w)])\n",
    "print([w for w in word_list if re.search(r'\\d+(\\.\\d+)?', w)])\n",
    "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', paranoid)\n",
    "nltk.re_show(r'\\w+|[^\\w\\s]+', paranoid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.583640Z",
     "start_time": "2025-02-25T09:37:20.418707Z"
    }
   },
   "id": "c2f2afbe41377ed2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Please} {could} {you} {stop} {the} {noise}?\n",
      "{I}'{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n",
      "{Please} could you stop the noise?\n",
      "{I}'m tryna get some rest\n",
      "{From} all the unborn chicken\n",
      "{Voices} in my head\n",
      "['pat', 'paut', 'peat', 'pet', 'piet', 'pit', 'poet', 'poot', 'pot', 'pout', 'put']\n",
      "[]\n",
      "{}P{}l{}e{}a{se }{}c{}o{}u{}l{}d{} {}y{}o{}u{} {}s{top}{} {}t{he }{}n{}o{}i{se?}{}\n",
      "{}I{}'{}m{} {}t{}r{}y{na get}{} {som}{}e{} {res}{}t{}\n",
      "{}F{rom al}{}l{} {}t{he }{}u{}n{bor}{}n{} {}c{hicken}{}\n",
      "{}V{}o{}i{ces in}{} {}m{}y{} {}h{}e{}a{}d{}\n",
      "{Please} {could} {you} {stop} {the} {noise}{?}\n",
      "{I}{'}{m} {tryna} {get} {some} {rest}\n",
      "{From} {all} {the} {unborn} {chicken}\n",
      "{Voices} {in} {my} {head}\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Write regular expressions to match the following classes of strings:\n",
    "\n",
    "1. A single determiner (assume that a, an, and the are the only determiners).\n",
    "2. An arithmetic expression using integers, addition, and multiplication, such as 2*3+8."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9abdfb7d784930"
  },
  {
   "cell_type": "code",
   "source": [
    "paranoid_full_raw = open('paranoid_full.txt')\n",
    "paranoid_full = paranoid_full_raw.read()\n",
    "nltk.re_show(r'(\\ban?\\b)|(\\bthe\\b)', paranoid_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.587600Z",
     "start_time": "2025-02-25T09:37:20.584394Z"
    }
   },
   "id": "e31c146a846ca13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please could you stop {the} noise?\n",
      "I'm tryna get some rest\n",
      "From all {the} unborn chicken\n",
      "Voices in my head\n",
      "What's that? (I may be paranoid, but not {an} android)\n",
      "What's that? (I may be paranoid, but not {an} android)\n",
      "When I am king\n",
      "You will be first against {the} wall\n",
      "With your opinion\n",
      "Which is of no consequence at all\n",
      "What's that? (I may be paranoid, but no android)\n",
      "What's that? (I may be paranoid, but no android)\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La, la\n",
      "Ambition makes you look pretty ugly\n",
      "Kicking, squealing, Gucci little piggy\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la\n",
      "You don't remember, you don't remember\n",
      "Why don't you remember my name?\n",
      "Off with his head, man, off with his head, man\n",
      "Why don't you remember my name?\n",
      "I guess he does\n",
      "Ah, oh, oh, oh\n",
      "Oh, oh, oh, oh\n",
      "Oh, oh\n",
      "Oh, oh\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From {a} great height\n",
      "From {a} great height, height\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From {a} great height\n",
      "From {a} great height, height\n",
      "that's it, sir, you're leaving\n",
      "The crackle of pigskin (rain down)\n",
      "(Come on rain down) {the} dust and {the} screaming\n",
      "The yuppies networking\n",
      "The panic, {the} vomit (from {a} great height)\n",
      "The panic, {the} vomit (from {a} great height)\n",
      "God loves his children\n",
      "God loves his children, yeah\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "arithmetics_7b = \"2+2+2+2+2, 2+2, 5*4, 73-74+73-74, 34/2, 2*3+8, banana, apple, DNA, 451Fahrenheit\" # {451}Fahrenheit is picked in both cases\n",
    "\n",
    "nltk.re_show(r'-?\\d+(\\s*[\\+\\*]\\s*-?\\d+)*', arithmetics_7b) # ChatGPT\n",
    "nltk.re_show(r'([^\\sa-zA-Z,]*[\\+\\*]*)*[^\\s,a-zA-Z]', arithmetics_7b) # my version "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.591929Z",
     "start_time": "2025-02-25T09:37:20.589056Z"
    }
   },
   "id": "9d690a524a3d3102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2+2+2+2+2}, {2+2}, {5*4}, {73}{-74+73}{-74}, {34}/{2}, {2*3+8}, banana, apple, DNA, {451}Fahrenheit\n",
      "{2+2+2+2+2}, {2+2}, {5*4}, {73-74+73-74}, {34/2}, {2*3+8}, banana, apple, DNA, {451}Fahrenheit\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8226bcde9bc96898"
  },
  {
   "cell_type": "code",
   "source": [
    "def url_opener(link):\n",
    "    url = link \n",
    "    response = request.urlopen(url) \n",
    "    raw = response.read().decode('utf8')\n",
    "    ready_url = BeautifulSoup(raw, 'html.parser').get_text()\n",
    "    print(ready_url) \n",
    "    \n",
    "url_opener('http://nltk.org/')\n",
    "# url_opener('https://mariaonoeva.github.io/Biennial2024/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:20.813192Z",
     "start_time": "2025-02-25T09:37:20.593556Z"
    }
   },
   "id": "ca2947c45db263da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK :: Natural Language Toolkit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK\n",
      "\n",
      "\n",
      "\n",
      "Documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK Documentation\n",
      "\n",
      "API Reference\n",
      "Example Usage\n",
      "Module Index\n",
      "Wiki\n",
      "FAQ\n",
      "Open Issues\n",
      "NLTK on GitHub\n",
      "\n",
      "Installation\n",
      "\n",
      "Installing NLTK\n",
      "Installing NLTK Data\n",
      "\n",
      "More\n",
      "\n",
      "Release Notes\n",
      "Contributing to NLTK\n",
      "NLTK Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Natural Language Toolkit¶\n",
      "NLTK is a leading platform for building Python programs to work with human language data.\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical\n",
      "resources such as WordNet,\n",
      "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\n",
      "wrappers for industrial-strength NLP libraries,\n",
      "and an active discussion forum.\n",
      "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\n",
      "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\n",
      "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
      "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\n",
      "and “an amazing library to play with natural language.”\n",
      "Natural Language Processing with Python provides a practical\n",
      "introduction to programming for language processing.\n",
      "Written by the creators of NLTK, it guides the reader through the fundamentals\n",
      "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\n",
      "and more.\n",
      "The online version of the book has been been updated for Python 3 and NLTK 3.\n",
      "(The original Python 2 version is still available at https://www.nltk.org/book_1ed.)\n",
      "\n",
      "Some simple things you can do with NLTK¶\n",
      "Tokenize and tag some text:\n",
      ">>> import nltk\n",
      ">>> sentence = \"\"\"At eight o'clock on Thursday morning\n",
      "... Arthur didn't feel very good.\"\"\"\n",
      ">>> tokens = nltk.word_tokenize(sentence)\n",
      ">>> tokens\n",
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning',\n",
      "'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
      ">>> tagged = nltk.pos_tag(tokens)\n",
      ">>> tagged[0:6]\n",
      "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'),\n",
      "('Thursday', 'NNP'), ('morning', 'NN')]\n",
      "\n",
      "\n",
      "Identify named entities:\n",
      ">>> entities = nltk.chunk.ne_chunk(tagged)\n",
      ">>> entities\n",
      "Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'),\n",
      "           ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'),\n",
      "       Tree('PERSON', [('Arthur', 'NNP')]),\n",
      "           ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'),\n",
      "           ('very', 'RB'), ('good', 'JJ'), ('.', '.')])\n",
      "\n",
      "\n",
      "Display a parse tree:\n",
      ">>> from nltk.corpus import treebank\n",
      ">>> t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
      ">>> t.draw()\n",
      "\n",
      "\n",
      "\n",
      "NB. If you publish work that uses NLTK, please cite the NLTK book as\n",
      "follows:\n",
      "\n",
      "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  O’Reilly Media Inc.\n",
      "\n",
      "\n",
      "\n",
      "Next Steps¶\n",
      "\n",
      "Sign up for release announcements\n",
      "Join in the discussion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " source\n",
      "\n",
      "\n",
      "3.9.1\n",
      "\n",
      "\n",
      "                    Aug 19, 2024\n",
      "                \n",
      "\n",
      "\n",
      "                © 2024, NLTK Project\n",
      "            \n",
      "\n",
      "            created with Sphinx and NLTK Theme\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.  Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "1. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multi-line regular expression, with inline comments, using the verbose flag (?x)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "622cd08fea2550f1"
  },
  {
   "cell_type": "code",
   "source": [
    "def load(my_text_raw): \n",
    "    my_text = open(my_text_raw)\n",
    "    my_text_read = my_text.read() \n",
    "    return my_text_read\n",
    "\n",
    "def punct_counter(my_text):\n",
    "    counter_list = []\n",
    "    punct = nltk.regexp_tokenize(load(my_text), r'[^\\w\\s\\d]')\n",
    "    for i in punct: \n",
    "        counter_list.append(punct.count(i))\n",
    "    ready_dict = dict(zip(punct, counter_list))\n",
    "    sorted_dict = dict(sorted(ready_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_dict.items()\n",
    "\n",
    "punct_counter('paranoid_full.txt')\n",
    "eng_HP = punct_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')\n",
    "ru_HP = punct_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1ru.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.694073Z",
     "start_time": "2025-02-25T09:37:20.814015Z"
    }
   },
   "id": "5c80419b6130c6c7",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "from tabulate import tabulate \n",
    "headers = ['Punctuation', 'Count']\n",
    "\n",
    "print(tabulate(eng_HP, headers=headers))\n",
    "print(tabulate(ru_HP, headers=headers))\n",
    "\n",
    "# I want them side by side \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.714134Z",
     "start_time": "2025-02-25T09:37:30.695826Z"
    }
   },
   "id": "3c311df5b5574fa9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation      Count\n",
      "-------------  -------\n",
      ".                 6136\n",
      ",                 5658\n",
      "\"                 4758\n",
      "'                 3141\n",
      "-                 1990\n",
      "?                  754\n",
      "!                  474\n",
      ";                  135\n",
      ":                   69\n",
      ")                   33\n",
      "(                   30\n",
      "*                    2\n",
      "~                    1\n",
      "\\                    1\n",
      "Punctuation      Count\n",
      "-------------  -------\n",
      ",                10190\n",
      ".                 6355\n",
      "—                 4598\n",
      "-                 1038\n",
      "…                  805\n",
      "?                  761\n",
      "!                  620\n",
      "«                  222\n",
      "»                  221\n",
      ":                  140\n",
      "*                  117\n",
      "(                   13\n",
      ")                   13\n",
      ";                    3\n",
      "№                    1\n",
      "“                    1\n",
      "”                    1\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Harry Potter 1 punctuation: Eng and Ru \n",
    "##### Eng: \n",
    "- why are there 30 of '(' and 33 of ')'? \n",
    "- questions: 754\n",
    "##### Ru: \n",
    "- same for Ru for kavychki, but skobki are even\n",
    "- so many commas??? \n",
    "- questions: 761 > 7 more > pretty consistent, I can imagine contexts where several questions mark used to express anger or surprise "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7ead94457cbb77"
  },
  {
   "cell_type": "code",
   "source": [
    "# ChatGPT to display the tables side by side\n",
    "# Generate table strings\n",
    "table1 = tabulate(eng_HP, headers=['Punctuation ENG', 'Count'], tablefmt='plain')\n",
    "table2 = tabulate(ru_HP, headers=['Punctuation RU', 'Count'], tablefmt='plain')\n",
    "\n",
    "# Split tables into lines\n",
    "lines1 = table1.split('\\n')\n",
    "lines2 = table2.split('\\n')\n",
    "\n",
    "# Determine the max width of the first table\n",
    "max_width = max(len(line) for line in lines1)\n",
    "\n",
    "# Determine the longer table for iteration\n",
    "longest_table_length = max(len(lines1), len(lines2))\n",
    "\n",
    "# Print tables side by side, handling uneven number of rows\n",
    "for i in range(longest_table_length):\n",
    "    line1 = lines1[i] if i < len(lines1) else \"\"\n",
    "    line2 = lines2[i] if i < len(lines2) else \"\"\n",
    "    print(f\"{line1.ljust(max_width)}    {line2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.720212Z",
     "start_time": "2025-02-25T09:37:30.716176Z"
    }
   },
   "id": "cc8336f6f19a8953",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation ENG      Count    Punctuation RU      Count\n",
      ".                     6136    ,                   10190\n",
      ",                     5658    .                    6355\n",
      "\"                     4758    —                    4598\n",
      "'                     3141    -                    1038\n",
      "-                     1990    …                     805\n",
      "?                      754    ?                     761\n",
      "!                      474    !                     620\n",
      ";                      135    «                     222\n",
      ":                       69    »                     221\n",
      ")                       33    :                     140\n",
      "(                       30    *                     117\n",
      "*                        2    (                      13\n",
      "~                        1    )                      13\n",
      "\\                        1    ;                       3\n",
      "                              №                       1\n",
      "                              “                       1\n",
      "                              ”                       1\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9. Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "2. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the following kinds of expression: monetary amounts; dates; names of people and organizations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc0647d4a5dd8fff"
  },
  {
   "cell_type": "code",
   "source": [
    "# monetary amounts? \n",
    "monetary_amounts = \"200$, 363524$, 587$, 65€, 8746CZK, 8₽, 9382₽, 87362513537CZK, Grand Theft Auto V, Corpus paper, April, Thursday, 76F, 17C\"\n",
    "money_pattern = r'\\d+([\\$€₽]|CZK)+' \n",
    "\n",
    "nltk.re_show(money_pattern, monetary_amounts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.724280Z",
     "start_time": "2025-02-25T09:37:30.721057Z"
    }
   },
   "id": "6ca3e7d8db41177",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200$}, {363524$}, {587$}, {65€}, {8746CZK}, {8₽}, {9382₽}, {87362513537CZK}, Grand Theft Auto V, Corpus paper, April, Thursday, 76F, 17C\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "# dates\n",
    "dates_more = '2024-04-04, 2024-04-05, Your Top Songs 2023, 2024-04-06, pinguin, 2024-04-07, 2024-04-08, Ice-cream, 2024-04-09, 2024-04-10, Sněžka'\n",
    "dates_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "nltk.re_show(dates_pattern, dates_more)\n",
    "\n",
    "# names of people and organizations\n",
    "names_pattern = r'[A-Z]+'\n",
    "nltk.re_show(names_pattern, dates_more)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.732006Z",
     "start_time": "2025-02-25T09:37:30.729142Z"
    }
   },
   "id": "1b58f300e8e7699f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2024-04-04}, {2024-04-05}, Your Top Songs 2023, {2024-04-06}, pinguin, {2024-04-07}, {2024-04-08}, Ice-cream, {2024-04-09}, {2024-04-10}, Sněžka\n",
      "2024-04-04, 2024-04-05, {Y}our {T}op {S}ongs 2023, 2024-04-06, pinguin, 2024-04-07, 2024-04-08, {I}ce-cream, 2024-04-09, 2024-04-10, {S}něžka\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 10. Rewrite the following loop as a list comprehension:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84957ac758b2034"
  },
  {
   "cell_type": "code",
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "result = []\n",
    "for word in sent:\n",
    "    word_len = (word, len(word))\n",
    "    result.append(word_len)\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.734531Z",
     "start_time": "2025-02-25T09:37:30.732725Z"
    }
   },
   "id": "9b0ca92465f42ddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "source": [
    "result_1 = [(word, len(word)) for word in sent] \n",
    "print(result_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.736826Z",
     "start_time": "2025-02-25T09:37:30.735207Z"
    }
   },
   "id": "7aac8030f89ad32f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 11. Define a string raw containing a sentence of your own choosing. Now, split raw on some character other than space, such as 's'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "113d57c6d2514ec0"
  },
  {
   "cell_type": "code",
   "source": [
    "born_this_way = \"\"\"Don't be a drag, just be a queen\n",
    "Whether you're broke or evergreen\n",
    "You're Black, white, beige, chola descent\n",
    "You're Lebanese, you're Orient'\n",
    "Whether life's disabilities left you outcast, bullied, or teased\n",
    "Rejoice and love yourself today\n",
    "'Cause, baby, you were born this way\"\"\" \n",
    "\n",
    "print(born_this_way.split('\\n'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.739306Z",
     "start_time": "2025-02-25T09:37:30.737507Z"
    }
   },
   "id": "ab29e93a45589d1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Don't be a drag, just be a queen\", \"Whether you're broke or evergreen\", \"You're Black, white, beige, chola descent\", \"You're Lebanese, you're Orient'\", \"Whether life's disabilities left you outcast, bullied, or teased\", 'Rejoice and love yourself today', \"'Cause, baby, you were born this way\"]\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 12. Write a for loop to print out the characters of a string, one per line."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d836e1587f2e8"
  },
  {
   "cell_type": "code",
   "source": [
    "dna = \"Same DNA, but born this way\"\n",
    "for char in dna: \n",
    "    print(char)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.741931Z",
     "start_time": "2025-02-25T09:37:30.740003Z"
    }
   },
   "id": "32b57d66464fe1eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "D\n",
      "N\n",
      "A\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "b\n",
      "o\n",
      "r\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "y\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 13. What is the difference between calling split on a string with no argument or with ' ' as the argument, e.g. sent.split() versus sent.split(' ')? What happens when the string being split contains tab characters, consecutive space characters, or a sequence of tabs and spaces? (In IDLE you will need to use '\\t' to enter a tab character.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110d93060b9aa65a"
  },
  {
   "cell_type": "code",
   "source": [
    "print(dna.split()) # space split\n",
    "print(dna.split(' ')) # same as the empty argument \n",
    "print(dna.split('\\t')) # no change because there is no tab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.744629Z",
     "start_time": "2025-02-25T09:37:30.742771Z"
    }
   },
   "id": "264bab69f5219b23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Same', 'DNA,', 'but', 'born', 'this', 'way']\n",
      "['Same', 'DNA,', 'but', 'born', 'this', 'way']\n",
      "['Same DNA, but born this way']\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 14. Create a variable words containing a list of words. Experiment with words.sort() and sorted(words). What is the difference?\n",
    "https://www.geeksforgeeks.org/python-difference-between-sorted-and-sort/ -- cool! "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad074d4668753642"
  },
  {
   "cell_type": "code",
   "source": [
    "dna_split = dna.split()\n",
    "print(dna_split.sort()) # none? why? > as per documentation returns None and changes the initial list \n",
    "print(sorted(dna_split)) # only returns the sorted list and makes no changes "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.746938Z",
     "start_time": "2025-02-25T09:37:30.745271Z"
    }
   },
   "id": "4cc79cf145c07a25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['DNA,', 'Same', 'born', 'but', 'this', 'way']\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 15.  Explore the difference between strings and integers by typing the following at a Python prompt: \"3\" * 7 and 3 * 7. Try converting between strings and integers using int(\"3\") and str(3)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65a5266eae4ba850"
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"3\"*7)\n",
    "print(3*7)\n",
    "print(int(\"3\")*7)\n",
    "print(str(3)*7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.749738Z",
     "start_time": "2025-02-25T09:37:30.747694Z"
    }
   },
   "id": "d89aef26c435e9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333\n",
      "21\n",
      "21\n",
      "3333333\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 16. Use a text editor to create a file called prog.py containing the single line monty = 'Monty Python'. Next, start up a new session with the Python interpreter, and enter the expression monty at the prompt. You will get an error from the interpreter. Now, try the following (note that you have to leave off the .py part of the filename).  This time, Python should return with a value. You can also try import prog, in which case Python should be able to evaluate the expression prog.monty at the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30a5bec7dd5fc3ba"
  },
  {
   "cell_type": "code",
   "source": [
    "from prog import monty\n",
    "monty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.754381Z",
     "start_time": "2025-02-25T09:37:30.750353Z"
    }
   },
   "id": "1d734dbb7e07359f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 17. What happens when the formatting strings %6s and %-6s are used to display strings that are longer than six characters?\n",
    "I don't get this... "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e39b9e25de659cdb"
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Number is : %6s\" % 'thisisaword')\n",
    "print(\"Number is : %-6s\" % 'thisisaword')\n",
    "print(\"Number is : %6s\" % 'aword')\n",
    "print(\"Number is : %-6s\" % 'aword')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:30.756830Z",
     "start_time": "2025-02-25T09:37:30.755038Z"
    }
   },
   "id": "325095e965e69c0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number is : thisisaword\n",
      "Number is : thisisaword\n",
      "Number is :  aword\n",
      "Number is : aword \n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 18. Read in some text from a corpus, tokenize it, and print the list of all wh-word types that occur. (wh-words in English are used in questions, relative clauses and exclamations: who, which, what, and so on.) Print them in order. Are any words duplicated in this list, because of the presence of case distinctions or punctuation?\n",
    "Woooow, I did it already in Chapter 2 but in a different way! \n",
    "- Well, I have some non-wh-words (whisperers, whirled, wheel, etc.), should I remove them? How to that without a wh-words list as in Chapter 2? \n",
    "- At the beginning I wanted to sum all duplicates, but now I sort of like that I have upper and lower case as separate lines because it shows different uses (interrogative and relative wh-words) \n",
    "- Updated wh_counter function, now it gives a table right away\n",
    "- idk i'll think about it later, the list way from Chapter 2 was easier in a way "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a6aca41587c28"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd \n",
    "def wh_counter(my_text):\n",
    "    counter_list = []\n",
    "    wh_raw = nltk.regexp_tokenize(load(my_text), r'^[Ww]h[a-z]+')\n",
    "    for i in wh_raw: \n",
    "        counter_list.append(wh_raw.count(i))\n",
    "    ready_dict = dict(zip(wh_raw, counter_list))\n",
    "    sorted_dict = dict(sorted(ready_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    output_wh_counter = pd.DataFrame(sorted_dict.items())\n",
    "    headers_wh = ['Wh-word', 'Count']\n",
    "    print(tabulate(output_wh_counter, headers=headers_wh))\n",
    "\n",
    "wh_counter('/Users/maria.onoeva/Desktop/new_folder/HP_1.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:31.736232Z",
     "start_time": "2025-02-25T09:37:30.757532Z"
    }
   },
   "id": "889c3256da8edb60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wh-word       Count\n",
      "--  ----------  -------\n",
      " 0  When             20\n",
      " 1  when             13\n",
      " 2  what             13\n",
      " 3  who              10\n",
      " 4  where             8\n",
      " 5  What              8\n",
      " 6  which             6\n",
      " 7  while             6\n",
      " 8  Where             6\n",
      " 9  whether           4\n",
      "10  While             3\n",
      "11  whatever          3\n",
      "12  white             2\n",
      "13  wheel             1\n",
      "14  whisperers        1\n",
      "15  whistled          1\n",
      "16  Who               1\n",
      "17  whole             1\n",
      "18  Whether           1\n",
      "19  Whispers          1\n",
      "20  Wheeling          1\n",
      "21  whirled           1\n",
      "22  Which             1\n",
      "23  why               1\n",
      "24  whirl             1\n",
      "25  Whatever          1\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 19. Create a file consisting of words and (made up) frequencies, where each line consists of a word, the space character, and a positive integer, e.g. fuzzy 53. Read the file into a Python list using open(filename).readlines(). Next, break each line into its two fields using split(), and convert the number into an integer using int(). The result should be a list of the form: [['fuzzy', 53], ...]. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84db07c177ea017"
  },
  {
   "cell_type": "code",
   "source": [
    "words_19 = load('chap3_ex19.txt')\n",
    "ex19 = [item.split() for item in words_19.split('\\n')]\n",
    "ex19_1 = [[item[0], int(item[1])] for item in ex19]\n",
    "\n",
    "print(ex19_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:31.739885Z",
     "start_time": "2025-02-25T09:37:31.736996Z"
    }
   },
   "id": "b13f0be8e7b93c08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['current', 56], ['file', 32], ['heat', 85], ['moment', 12], ['by', 47], ['my', 36], ['side', 93]]\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 20. Write code to access a favorite webpage and extract some text from it. For example, access a weather site and extract the forecast top temperature for your town or city today. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89abf166736c7d66"
  },
  {
   "cell_type": "code",
   "source": [
    "def url_opener_Return(link):\n",
    "    url = link \n",
    "    response = request.urlopen(url) \n",
    "    raw = response.read().decode('utf8')\n",
    "    ready_url = BeautifulSoup(raw, 'html.parser').get_text()\n",
    "    return ready_url\n",
    "    \n",
    "url_opener_Return('https://www.bbc.com/weather/3067696')[1375:1596]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:32.486468Z",
     "start_time": "2025-02-25T09:37:31.740617Z"
    }
   },
   "id": "f867ef092c60a8e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day forecastLast updated today at 10:00Today, Sunny intervals and light windsSunny IntervalsSunny Intervals, High12° 53°Low3° 38°, Wind speed6 mph9 km/h NE6 mph9 km/hNorth EasterlySunny intervals and light windsWednesday\\xa0'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 21. Write a function unknown() that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using re.findall()) and remove any items from this set that occur in the Words Corpus (nltk.corpus.words). Try to categorize these words manually and discuss your findings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9b8229dbd005df"
  },
  {
   "cell_type": "code",
   "source": [
    "def unknown(link):\n",
    "    link_text = url_opener_Return(link)\n",
    "    lower_all_words = [w.lower() for w in nltk.corpus.words.words()]\n",
    "    list_words = [w.lower() for w in word_tokenize(link_text) if w.isalpha()]\n",
    "    final_list = []\n",
    "    for word in list_words:\n",
    "        if word not in lower_all_words:\n",
    "            final_list.append(word)    \n",
    "    print(set(final_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:32.489757Z",
     "start_time": "2025-02-25T09:37:32.487368Z"
    }
   },
   "id": "2b6ecfde30a4603d",
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": [
    "unknown('https://www.cyberpunk.net/us/en/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.008382Z",
     "start_time": "2025-02-25T09:37:32.490588Z"
    }
   },
   "id": "50a233d3d0f7599c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'games', 'rights', 'submitfind', 'redenenglishрусскийdeutschpolskiportuguês', 'moregamescyberpunk', 'declarationredmodenglishenglishрусскийdeutschpolskiportuguês', 'morelearn', 'offers', 'italiano日本語한국어简体中文繁體中文العربيةbuy', 'logo', 'trailerlearn', 'recaptcha', 'françaisespañolespañol', 'policycareersuser', 'cyberpunk', 'things', 'bookletmoreupdate', 'stories', 'addressenter', 'rpg', 'edgerunners', 'guidelinescookie', 'gamespot', 'libertyshowsedgerunnerscommunityforumsdiscordcosplay', 'onterms', 'eurogamerget', 'cd', 'email', 'announced', 'terms', 'plannergame', 'google', 'experiencelearn', 'trademarks', 'protected', 'reboot', 'mx', 'morewatch', 'futureimmerse', 'projekt', 'guidesbuild', 'countries', 'storyline', 'br', 'announcements', 'rewardsmerchandisemediasupportcd', 'years', 'agreementfan'}\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 22. Examine the results of processing the URL http://news.bbc.co.uk/ using the regular expressions suggested above. You will see that there is still a fair amount of non-textual data there, particularly Javascript commands. You may also find that sentence breaks have not been properly preserved. Define further regular expressions that improve the extraction of text from this web page."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7156b0883f912dd"
  },
  {
   "cell_type": "code",
   "source": [
    "bbc_web = url_opener_Return('http://news.bbc.co.uk/')\n",
    "nltk.re_show(r'[A-Z][a-z]*', bbc_web)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.371562Z",
     "start_time": "2025-02-25T09:37:33.009141Z"
    }
   },
   "id": "c6e867574b2d99b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Home} - {B}{B}{C} {News}{B}{B}{C} {Homepage}{Skip} to content{Accessibility} {Help}{Your} account{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{Culture}{Future}{Music}{T}{V}{Weather}{Sounds}{More} menu{More} menu{Search} {B}{B}{C}{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{Culture}{Future}{Music}{T}{V}{Weather}{Sounds}{Close} menu{B}{B}{C} {News}{Menu}{Home}{Israel}-{Gaza} war{War} in {Ukraine}{Climate}{Video}{World}{U}{K}{Business}{Tech}{Science}{More}{Entertainment} & {Arts}{Health}{World} {News} {T}{V}{In} {Pictures}{B}{B}{C} {Verify}{Newsbeat}{Sign} {In} {Banner}{Discover} your {B}{B}{C}{Sign} in or create an account to watch, listen and join in{Sign} inor{Register}{Close} sign in banner{B}{B}{C} {News}{Energy} bills to rise by more than expected in {April}{Regulator} {Ofgem} says a household using a typical amount of energy will see its annual bill rise by £111.{Attribution}{Business}{Posted}1 hour ago1h{Live}. {Macron} suggests {Ukraine}-{Russia} truce could be weeks away after talks with {Trump}{Attribution}{Europe}{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} {Attribution}{World}{Posted}7 hours ago7h{Patients}' concerns as hospital shake-up consultation closes{Attribution}{Northern} {Ireland}{Posted}42 minutes ago42min{New} powers to search homes for stolen phones{Attribution}{Politics}{Posted}40 minutes ago40min{Artists} release silent album in protest at {A}{I} copyright proposals{Attribution}{Culture}{Posted}55 minutes ago55min{Generation} {K}: {The} disturbing rise of ketamine abuse among young people{Attribution}{B}{B}{C} {In}{Depth}{Posted}3 hours ago3h{Progress} of baby abandoned near footpath is 'astonishing', court told{Attribution}{London}{Posted}3 hours ago3h{Women}'s abuse online: '{I} get trolled every second, every day'{Attribution}{Technology}{Posted}9 hours ago9h{New} rules on food smuggling between {N}{I} and {G}{B} in place{Attribution}{Northern} {Ireland} {Politics}{Posted}1 hour ago1h{First} place in {British} {Isles} set to approve right to die{Attribution}{Isle} of {Man}{Posted}9 hours ago9h{Jailed} {M}{P} {Mike} {Amesbury} urged to quit {Commons}{Attribution}{Liverpool}{Posted}25 minutes ago25min{Federal} workers left confused as {Musk} doubles down on threat{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Northern} {Ireland}{Energy} bills to rise by more than expected in {April}{Regulator} {Ofgem} says a household using a typical amount of energy will see its annual bill rise by £111.{Attribution}{Business}{Posted}1 hour ago1h{Live}. {Macron} suggests {Ukraine}-{Russia} truce could be weeks away after talks with {Trump}{Attribution}{Europe}{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} {Attribution}{World}{Posted}7 hours ago7h{New} powers to search homes for stolen phones{Attribution}{Politics}{Posted}40 minutes ago40min{Artists} release silent album in protest at {A}{I} copyright proposals{Attribution}{Culture}{Posted}55 minutes ago55min{Generation} {K}: {The} disturbing rise of ketamine abuse among young people{Attribution}{B}{B}{C} {In}{Depth}{Posted}3 hours ago3h{Progress} of baby abandoned near footpath is 'astonishing', court told{Attribution}{London}{Posted}3 hours ago3h{Women}'s abuse online: '{I} get trolled every second, every day'{Attribution}{Technology}{Posted}9 hours ago9h{First} place in {British} {Isles} set to approve right to die{Attribution}{Isle} of {Man}{Posted}9 hours ago9h{Jailed} {M}{P} {Mike} {Amesbury} urged to quit {Commons}{Attribution}{Liverpool}{Posted}25 minutes ago25min{Federal} workers left confused as {Musk} doubles down on threat{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{U}{K} fooled by faith in international law, says {Badenoch}{Attribution}{Politics}{Posted}11 hours ago11h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Wales}{Energy} bills to rise by more than expected in {April}{Regulator} {Ofgem} says a household using a typical amount of energy will see its annual bill rise by £111.{Attribution}{Business}{Posted}1 hour ago1h{Live}. {Macron} suggests {Ukraine}-{Russia} truce could be weeks away after talks with {Trump}{Attribution}{Europe}{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} {Attribution}{World}{Posted}7 hours ago7h{New} powers to search homes for stolen phones{Attribution}{Politics}{Posted}40 minutes ago40min{Artists} release silent album in protest at {A}{I} copyright proposals{Attribution}{Culture}{Posted}55 minutes ago55min{Generation} {K}: {The} disturbing rise of ketamine abuse among young people{Attribution}{B}{B}{C} {In}{Depth}{Posted}3 hours ago3h{Progress} of baby abandoned near footpath is 'astonishing', court told{Attribution}{London}{Posted}3 hours ago3h{Women}'s abuse online: '{I} get trolled every second, every day'{Attribution}{Technology}{Posted}9 hours ago9h{First} place in {British} {Isles} set to approve right to die{Attribution}{Isle} of {Man}{Posted}9 hours ago9h{Jailed} {M}{P} {Mike} {Amesbury} urged to quit {Commons}{Attribution}{Liverpool}{Posted}25 minutes ago25min{Federal} workers left confused as {Musk} doubles down on threat{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{U}{K} fooled by faith in international law, says {Badenoch}{Attribution}{Politics}{Posted}11 hours ago11h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {Scotland}{Energy} bills to rise by more than expected in {April}{Regulator} {Ofgem} says a household using a typical amount of energy will see its annual bill rise by £111.{Attribution}{Business}{Posted}1 hour ago1h{Live}. {Macron} suggests {Ukraine}-{Russia} truce could be weeks away after talks with {Trump}{Attribution}{Europe}{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} {Attribution}{World}{Posted}7 hours ago7h{New} powers to search homes for stolen phones{Attribution}{Politics}{Posted}40 minutes ago40min{Artists} release silent album in protest at {A}{I} copyright proposals{Attribution}{Culture}{Posted}55 minutes ago55min{Generation} {K}: {The} disturbing rise of ketamine abuse among young people{Attribution}{B}{B}{C} {In}{Depth}{Posted}3 hours ago3h{Progress} of baby abandoned near footpath is 'astonishing', court told{Attribution}{London}{Posted}3 hours ago3h{Women}'s abuse online: '{I} get trolled every second, every day'{Attribution}{Technology}{Posted}9 hours ago9h{First} place in {British} {Isles} set to approve right to die{Attribution}{Isle} of {Man}{Posted}9 hours ago9h{Jailed} {M}{P} {Mike} {Amesbury} urged to quit {Commons}{Attribution}{Liverpool}{Posted}25 minutes ago25min{Federal} workers left confused as {Musk} doubles down on threat{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{U}{K} fooled by faith in international law, says {Badenoch}{Attribution}{Politics}{Posted}11 hours ago11h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for {England}{Energy} bills to rise by more than expected in {April}{Regulator} {Ofgem} says a household using a typical amount of energy will see its annual bill rise by £111.{Attribution}{Business}{Posted}1 hour ago1h{Live}. {Macron} suggests {Ukraine}-{Russia} truce could be weeks away after talks with {Trump}{Attribution}{Europe}{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} {Attribution}{World}{Posted}7 hours ago7h{New} powers to search homes for stolen phones{Attribution}{Politics}{Posted}40 minutes ago40min{Artists} release silent album in protest at {A}{I} copyright proposals{Attribution}{Culture}{Posted}55 minutes ago55min{Generation} {K}: {The} disturbing rise of ketamine abuse among young people{Attribution}{B}{B}{C} {In}{Depth}{Posted}3 hours ago3h{Progress} of baby abandoned near footpath is 'astonishing', court told{Attribution}{London}{Posted}3 hours ago3h{Women}'s abuse online: '{I} get trolled every second, every day'{Attribution}{Technology}{Posted}9 hours ago9h{First} place in {British} {Isles} set to approve right to die{Attribution}{Isle} of {Man}{Posted}9 hours ago9h{Jailed} {M}{P} {Mike} {Amesbury} urged to quit {Commons}{Attribution}{Liverpool}{Posted}25 minutes ago25min{Federal} workers left confused as {Musk} doubles down on threat{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{U}{K} fooled by faith in international law, says {Badenoch}{Attribution}{Politics}{Posted}11 hours ago11h{Change} my nationclose panel{Change} my nation{Change} your nation to get more top stories from where you are, as well as the {U}{K} and international headlines.{United} {Kingdom}{England}{Scotland}{Wales}{Northern} {Ireland}{Confirm}{You} are now seeing top stories for the {U}{K}{More} to explore{Oscars} 2025: {The} quirks, record breakers and possible winners{When} was the last time two musicals were up for best picture? {And} could {Adrien} {Brody} break a record?{Attribution}{U}{S} & {Canada}{Posted}9 hours ago9h{How} much are energy bills going up?{Attribution}{Business}{Posted}1 hour ago1h{Macron} walks tightrope with {Trump} as he makes {Europe}'s case on {Ukraine}{Attribution}{World}{Posted}7 hours ago7h{Five} key takeaways from the {German} election{Attribution}{Europe}{Posted}16 hours ago16h{The} {Papers}: '{Ukraine} peace in weeks' and 'killer planned school shooting'{Attribution}{The} {Papers}{Posted}9 hours ago9h{U}{S} {Politics} {Unspun}{Cut} through the noise with {North} {America} correspondent {Anthony} {Zurcher}’s newsletter.{Sign} up here{Most} watched1{East}{Enders} star says wife not over the moon at {Martin}'s exit2{Man} arrested trying to smuggle cocaine under toupee3{Mystery} surrounds loud explosion-like sound4{Watch}: {East}{Enders} actors share their most iconic scenes5{Watch}: {Police} officer dressed as the {Grinch} leads drug raid{Published}22 {December} 2024{Also} in news{Murdered} businessman's body found in sack with hands and legs tied{Campbell} {Scott} disappeared from a luxury hotel before being found miles outside {Nairobi} by a cattle herder.{Attribution}{Edinburgh}, {Fife} & {East}{Posted}31 minutes ago31min{People} will starve because of {U}{S} aid cut to {Sudan}, humanitarian worker warns{Attribution}{Africa}{Posted}9 hours ago9h{Teenager}'s school shooting plan 'extremely shocking'{Attribution}{Beds}, {Herts} & {Bucks}{Posted}54 minutes ago54min{Israel} demands complete demilitarisation of southern {Syria}{Attribution}{Middle} {East}{Posted}12 hours ago12h{Secret} {Service} agent who leapt onto {J}{F}{K}'s car during assassination dies at 93{Attribution}{U}{S} & {Canada}{Posted}6 hours ago6h{Major} {Asia} bank to cut 4,000 roles as {A}{I} replaces humans{Attribution}{Business}{Posted}5 hours ago5h{Trump} dominates {Liberal} leadership debate in {Canada}{Attribution}{U}{S} & {Canada}{Posted}5 hours ago5h{Most} read1{Abandoned} baby {Elsa}'s progress 'astonishing', court told2{U}{S} sides with {Russia} in {U}{N} resolutions on {Ukraine} 3'{Ukraine} peace in weeks' and 'killer planned school shooting'4{Energy} bills to rise by more than expected in {April}5{Artists} release silent album in protest against {A}{I} using their work6{New} powers to search homes for stolen phones7{U}{K} fooled by faith in international law, says {Badenoch}8{Generation} {K}: {The} disturbing rise of ketamine abuse among young people9{Women}'s abuse online: '{I} get trolled every second, every day'10{First} place in {British} {Isles} set to approve right to die{B}{B}{C} {News} app{Top} stories, breaking news, live reporting, and follow news topics that match your interests{B}{B}{C} {News} app{More} news on i{Player} and {Sounds}{Watch} live on i{Player}{Listen} to {Live} {News} on {Sounds}{The} {Macron} {And} {Trump} {Bromance} {Returns}. {Audio}, 32 minutes{The} {Macron} {And} {Trump} {Bromance} {Returns}{Attribution}{B}{B}{C} {News}{Americanswers}... on 5 {Live}! {What}'s {Elon} {Musk}'s latest threat to federal workers? {Audio}, 32 minutes{Americanswers}... on 5 {Live}! {What}'s {Elon} {Musk}'s latest threat to federal workers?{Attribution}{B}{B}{C} {News}{Elsewhere} on the {B}{B}{C}{New} comedy from the producer of {This} {Country}{Meet} the '{Funboys}', three emotionally-unassembled young men making the most of small-town life{Attributioni}{Player}{How} has science fiction shaped {Elon} {Musk}?{Attribution}{Sounds}{What} does it take to win {Europe}'s coveted football trophy?{Attributioni}{Player}{Travel} to 16th-century {Mexico} to learn about {Hern}án {Cort}és{Attribution}{Sounds}{The} acclaimed series, {Forensics}: the {Real} {C}{S}{I}, returns soon{Attributioni}{Player}{Hafez} reflects on competing at {Paris} 2024 while pregnant{Attribution}{Sounds}{Katya} {Adler} returns to the {Balkans} 30 years on{Attributioni}{Player}{Sport}{Live}. {Premier} {League} build-up and news conferences{All} the football latest with {Liverpool}, {Newcastle} and {Arsenal} news conferences and build-up to the midweek games.{Attribution}{Football}{Leeds} stun {Sheff} {Utd} with comeback to go five clear{Attribution}{Championship}{Posted}10 hours ago10h{Comments}1307{Galatasaray} accuse {Mourinho} of making 'racist statements'{Attribution}{European} {Football}{Posted}9 hours ago9h{Live}. {Champions} {Trophy}: {Australia} v {South} {Africa} delayed by rain{Attribution}{Cricket}{Lions} watch week three: {Fly}-halves, back three & captain{Attribution}{Rugby} {Union}{Posted}2 hours ago2h{Comments}280{Thomas} aims to complete journey from 'nobody' to major finals{Attribution}{Scotland} {Women}{Posted}1 hour ago1h{Fashion} forwards: {Great} goals in great {Premier} {League} kits. {Video}, 00:03:26{Fashion} forwards: {Great} goals in great {Premier} {League} kits{Attribution}{Premier} {League}{Posted}2 hours ago2h3:26{View} more{News} alerts{Report} an issue{Send} a story{Why} you can trust {B}{B}{C} {News}{Instagram}{Tik}{Tok}{Facebook}{X}{Home}{News}{Sport}{Earth}{Reel}{Worklife}{Travel}{Culture}{Future}{Music}{T}{V}{Weather}{Sounds}{Terms} of {Use}{About} the {B}{B}{C}{Privacy} {Policy}{Cookies}{Accessibility} {Help}{Parental} {Guidance}{Contact} the {B}{B}{C}{B}{B}{C} emails for you{Advertise} with us{Copyright} © 2025 {B}{B}{C}. {The} {B}{B}{C} is not responsible for the content of external sites. {Read} about our approach to external linking.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 23. Are you able to write a regular expression to tokenize text in such a way that the word don't is tokenized into do and n't? Explain why this regular expression won't work: «n't|\\w+».\n",
    "It works, but it also matches all dos as in 'down' etc. Can I fix it? -- yes! using lookahead '?=n\\'t'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf031c9f68cd902"
  },
  {
   "cell_type": "code",
   "source": [
    "ex22 = r'n\\'t|\\w+' \n",
    "ex22_me = r'don\\'t'\n",
    "ex22_me1 = r'n\\'t|do(?=n\\'t)'\n",
    "nltk.re_show(ex22_me1, paranoid_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.374168Z",
     "start_time": "2025-02-25T09:37:33.372232Z"
    }
   },
   "id": "f4b8f5697f71948c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please could you stop the noise?\n",
      "I'm tryna get some rest\n",
      "From all the unborn chicken\n",
      "Voices in my head\n",
      "What's that? (I may be paranoid, but not an android)\n",
      "What's that? (I may be paranoid, but not an android)\n",
      "When I am king\n",
      "You will be first against the wall\n",
      "With your opinion\n",
      "Which is of no consequence at all\n",
      "What's that? (I may be paranoid, but no android)\n",
      "What's that? (I may be paranoid, but no android)\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La, la\n",
      "Ambition makes you look pretty ugly\n",
      "Kicking, squealing, Gucci little piggy\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la-la-la-la\n",
      "La-la-la\n",
      "You {do}{n't} remember, you {do}{n't} remember\n",
      "Why {do}{n't} you remember my name?\n",
      "Off with his head, man, off with his head, man\n",
      "Why {do}{n't} you remember my name?\n",
      "I guess he does\n",
      "Ah, oh, oh, oh\n",
      "Oh, oh, oh, oh\n",
      "Oh, oh\n",
      "Oh, oh\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From a great height\n",
      "From a great height, height\n",
      "Rain down, rain down\n",
      "Come on, rain down on me\n",
      "From a great height\n",
      "From a great height, height\n",
      "that's it, sir, you're leaving\n",
      "The crackle of pigskin (rain down)\n",
      "(Come on rain down) the dust and the screaming\n",
      "The yuppies networking\n",
      "The panic, the vomit (from a great height)\n",
      "The panic, the vomit (from a great height)\n",
      "God loves his children\n",
      "God loves his children, yeah\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 24. Try to write code to convert text into hAck3r, using regular expressions and substitution, where e → 3, i → 1, o → 0, l → |, s → 5, . → 5w33t!, ate → 8. Normalize the text to lowercase before converting it. Add more substitutions of your own. Now try to map s to two different values: $ for word-initial s, and 5 for word-internal s."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4dfd8236cbc83a"
  },
  {
   "cell_type": "code",
   "source": [
    "paranoid_full_ex24 = paranoid_full.lower() \n",
    "\n",
    "# idk how to do it in a more sophisticated way\n",
    "paranoid_full_ex24 = re.sub(r'e', '3', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'i', '1', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'o', '1', paranoid_full_ex24)   \n",
    "paranoid_full_ex24 = re.sub(r'l', '|', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'\\.', '5w33t!', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'ate', '8', paranoid_full_ex24)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.377315Z",
     "start_time": "2025-02-25T09:37:33.374787Z"
    }
   },
   "id": "4185307123764633",
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "source": [
    "paranoid_full_ex24 = paranoid_full.lower() \n",
    "paranoid_full_ex24 = re.sub(r'\\ss', ' $', paranoid_full_ex24)\n",
    "paranoid_full_ex24 = re.sub(r'(?<!\\b)s', '5', paranoid_full_ex24)\n",
    "print(paranoid_full_ex24)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.380020Z",
     "start_time": "2025-02-25T09:37:33.378015Z"
    }
   },
   "id": "6ff454c008a294",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plea5e could you $top the noi5e?\n",
      "i'm tryna get $ome re5t\n",
      "from all the unborn chicken\n",
      "voice5 in my head\n",
      "what's that? (i may be paranoid, but not an android)\n",
      "what's that? (i may be paranoid, but not an android)\n",
      "when i am king\n",
      "you will be fir5t again5t the wall\n",
      "with your opinion\n",
      "which i5 of no con5equence at all\n",
      "what's that? (i may be paranoid, but no android)\n",
      "what's that? (i may be paranoid, but no android)\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la, la\n",
      "ambition make5 you look pretty ugly\n",
      "kicking, $quealing, gucci little piggy\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la-la-la-la\n",
      "la-la-la\n",
      "you don't remember, you don't remember\n",
      "why don't you remember my name?\n",
      "off with hi5 head, man, off with hi5 head, man\n",
      "why don't you remember my name?\n",
      "i gue55 he doe5\n",
      "ah, oh, oh, oh\n",
      "oh, oh, oh, oh\n",
      "oh, oh\n",
      "oh, oh\n",
      "rain down, rain down\n",
      "come on, rain down on me\n",
      "from a great height\n",
      "from a great height, height\n",
      "rain down, rain down\n",
      "come on, rain down on me\n",
      "from a great height\n",
      "from a great height, height\n",
      "that's it, $ir, you're leaving\n",
      "the crackle of pig5kin (rain down)\n",
      "(come on rain down) the du5t and the $creaming\n",
      "the yuppie5 networking\n",
      "the panic, the vomit (from a great height)\n",
      "the panic, the vomit (from a great height)\n",
      "god love5 hi5 children\n",
      "god love5 hi5 children, yeah\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "source": [
    "# from ChatGPT > I don't know '|'.join, re.escape and re.compile and don't remember how lambda works :( \n",
    "# Define the replacements\n",
    "replacements = {\n",
    "    'e': '3',\n",
    "    'i': '1',\n",
    "    'o': '0',\n",
    "    'l': '|',\n",
    "    's': '5',\n",
    "    '.': '5w33t!',\n",
    "    'ate': '8'\n",
    "}\n",
    "\n",
    "# Define a function to perform the replacements\n",
    "def replace_chars(text, replacements):\n",
    "    pattern = re.compile('|'.join(re.escape(key) for key in replacements.keys()))\n",
    "    return pattern.sub(lambda x: replacements[x.group()], text)\n",
    "\n",
    "# Apply the replacements\n",
    "paranoid_full_ex24_gpt = replace_chars(paranoid_full_ex24, replacements)\n",
    "print(paranoid_full_ex24_gpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:33.383400Z",
     "start_time": "2025-02-25T09:37:33.380700Z"
    }
   },
   "id": "b609f3561a9c1a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p|3a53 c0u|d y0u $t0p th3 n0153?\n",
      "1'm tryna g3t $0m3 r35t\n",
      "fr0m a|| th3 unb0rn ch1ck3n\n",
      "v01c35 1n my h3ad\n",
      "what'5 that? (1 may b3 paran01d, but n0t an andr01d)\n",
      "what'5 that? (1 may b3 paran01d, but n0t an andr01d)\n",
      "wh3n 1 am k1ng\n",
      "y0u w1|| b3 f1r5t aga1n5t th3 wa||\n",
      "w1th y0ur 0p1n10n\n",
      "wh1ch 15 0f n0 c0n53qu3nc3 at a||\n",
      "what'5 that? (1 may b3 paran01d, but n0 andr01d)\n",
      "what'5 that? (1 may b3 paran01d, but n0 andr01d)\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a, |a\n",
      "amb1t10n mak35 y0u |00k pr3tty ug|y\n",
      "k1ck1ng, $qu3a|1ng, gucc1 |1tt|3 p1ggy\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a-|a-|a-|a\n",
      "|a-|a-|a\n",
      "y0u d0n't r3m3mb3r, y0u d0n't r3m3mb3r\n",
      "why d0n't y0u r3m3mb3r my nam3?\n",
      "0ff w1th h15 h3ad, man, 0ff w1th h15 h3ad, man\n",
      "why d0n't y0u r3m3mb3r my nam3?\n",
      "1 gu355 h3 d035\n",
      "ah, 0h, 0h, 0h\n",
      "0h, 0h, 0h, 0h\n",
      "0h, 0h\n",
      "0h, 0h\n",
      "ra1n d0wn, ra1n d0wn\n",
      "c0m3 0n, ra1n d0wn 0n m3\n",
      "fr0m a gr3at h31ght\n",
      "fr0m a gr3at h31ght, h31ght\n",
      "ra1n d0wn, ra1n d0wn\n",
      "c0m3 0n, ra1n d0wn 0n m3\n",
      "fr0m a gr3at h31ght\n",
      "fr0m a gr3at h31ght, h31ght\n",
      "that'5 1t, $1r, y0u'r3 |3av1ng\n",
      "th3 crack|3 0f p1g5k1n (ra1n d0wn)\n",
      "(c0m3 0n ra1n d0wn) th3 du5t and th3 $cr3am1ng\n",
      "th3 yupp135 n3tw0rk1ng\n",
      "th3 pan1c, th3 v0m1t (fr0m a gr3at h31ght)\n",
      "th3 pan1c, th3 v0m1t (fr0m a gr3at h31ght)\n",
      "g0d |0v35 h15 ch1|dr3n\n",
      "g0d |0v35 h15 ch1|dr3n, y3ah\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 25. Pig Latin is a simple transformation of English text. Each word of the text is converted as follows: move any consonant (or consonant cluster) that appears at the start of the word to the end, then append ay, e.g. string → ingstray, idle → idleay. http://en.wikipedia.org/wiki/Pig_Latin\n",
    "\n",
    "- Write a function to convert a word to Pig Latin.\n",
    "- Write code that converts text, instead of individual words.\n",
    "- Extend it further to preserve capitalization, to keep qu together (i.e. so that quiet becomes ietquay), and to detect when y is used as a consonant (e.g. yellow) vs a vowel (e.g. style)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7396508de0d06f1"
  },
  {
   "cell_type": "code",
   "source": [
    "# converting a word \n",
    "def pig_word(): \n",
    "    word = input('Enter a word: ')\n",
    "    consonant_re = r'[^aeiyuo]+(?=[aeiyuo])'\n",
    "    try: \n",
    "        consonant = re.search(consonant_re, word).group(0)\n",
    "        output_word = word[len(consonant):] + consonant + 'ay'\n",
    "    except: # if the error (no pattern) is raised, then do this \n",
    "        output_word = word + 'ay'\n",
    "    print(f'You have entered {word.upper()} \\n Output is {output_word.upper()}')\n",
    "\n",
    "pig_word()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:38.275784Z",
     "start_time": "2025-02-25T09:37:33.384093Z"
    }
   },
   "id": "17baa9fe614755aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have entered CAT \n",
      " Output is ATCAY\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "source": [
    "# converting a text\n",
    "def pig_word_for_text(word): \n",
    "    consonant_re = r'[^aeiyuo]+(?=[aeiyuo])'\n",
    "    try: \n",
    "        consonant = re.search(consonant_re, word).group(0)\n",
    "        output_word = word[len(consonant):] + consonant + 'ay'\n",
    "    except: # if the error (no pattern) is raised, then do this \n",
    "        output_word = word + 'ay'\n",
    "    return output_word\n",
    "\n",
    "def pig_text(text):\n",
    "    text = [word.lower() for word in text.split() if word.isalpha()]\n",
    "    print([pig_word_for_text(word) for word in text])\n",
    "        \n",
    "pig_text(paranoid_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T09:37:38.283487Z",
     "start_time": "2025-02-25T09:37:38.277560Z"
    }
   },
   "id": "39434fa758eb8793",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easeplay', 'ouldcay', 'youay', 'opstay', 'ethay', 'ynatray', 'etgay', 'omesay', 'estray', 'omfray', 'allay', 'ethay', 'bornnbay', 'ickenchay', 'oicesvay', 'inay', 'ymay', 'eadhay', 'aymay', 'ebay', 'utbay', 'otnay', 'anay', 'aymay', 'ebay', 'utbay', 'otnay', 'anay', 'enwhay', 'iay', 'amay', 'ingkay', 'youay', 'illway', 'ebay', 'irstfay', 'gainstgay', 'ethay', 'allway', 'ithway', 'youray', 'pinionpay', 'ichwhay', 'isay', 'ofay', 'onay', 'onsequencecay', 'atay', 'allay', 'aymay', 'ebay', 'utbay', 'onay', 'aymay', 'ebay', 'utbay', 'onay', 'alay', 'bitionmbay', 'akesmay', 'youay', 'ooklay', 'ettypray', 'lyglay', 'uccigay', 'ittlelay', 'iggypay', 'youay', 'youay', 'ememberray', 'ywhay', 'youay', 'ememberray', 'ymay', 'offay', 'ithway', 'ishay', 'offay', 'ithway', 'ishay', 'anmay', 'ywhay', 'youay', 'ememberray', 'ymay', 'iay', 'uessgay', 'ehay', 'oesday', 'ohay', 'ohay', 'ohay', 'ohay', 'ainray', 'ainray', 'ownday', 'omecay', 'ainray', 'ownday', 'onay', 'emay', 'omfray', 'aay', 'eatgray', 'eighthay', 'omfray', 'aay', 'eatgray', 'eighthay', 'ainray', 'ainray', 'ownday', 'omecay', 'ainray', 'ownday', 'onay', 'emay', 'omfray', 'aay', 'eatgray', 'eighthay', 'omfray', 'aay', 'eatgray', 'eighthay', 'eavinglay', 'ethay', 'acklecray', 'ofay', 'igskinpay', 'onay', 'ainray', 'ethay', 'ustday', 'anday', 'ethay', 'eamingscray', 'ethay', 'ppiesppay', 'etworkingnay', 'ethay', 'ethay', 'omitvay', 'aay', 'eatgray', 'ethay', 'ethay', 'omitvay', 'aay', 'eatgray', 'odgay', 'oveslay', 'ishay', 'ildrenchay', 'odgay', 'oveslay', 'ishay', 'yeahay']\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 26. Download some text from a language that has vowel harmony (e.g. Hungarian), extract the vowel sequences of words, and create a vowel bigram table.\n",
    "-[x] Loading Hungarian text to variable <code>hun_text</code>\n",
    "-[x] Splitting by word because I need it for each word\n",
    "-[x] Then I need to use regex to extract all sounds from words \n",
    "-[x] Then count unique patterns \n"
   ],
   "id": "a2d7572024c1bbb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:35:16.923214Z",
     "start_time": "2025-02-25T10:35:16.907205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "hun_text = load('Hung_lorum_ipse.txt')\n",
    "hun_words = [word.lower() for word in hun_text.split() if word.isalpha()]\n",
    "vowels_hung = r'[aeiouöüáéíóúőű]' \n",
    "\n",
    "vowels_words = [(re.findall(vowels_hung, word)) for word in hun_words]\n",
    "unique_vowel_patterns = Counter(map(tuple, vowels_words))\n",
    "print(unique_vowel_patterns)"
   ],
   "id": "9381901d07be9069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('a',): 74, ('é',): 31, ('e',): 23, ('a', 'a'): 14, ('o', 'á'): 12, ('i',): 10, ('e', 'e'): 8, ('o',): 7, ('é', 'e', 'e'): 7, ('e', 'ő'): 6, ('a', 'a', 'o', 'á'): 6, ('i', 'e'): 5, ('a', 'o'): 5, ('o', 'o'): 5, ('á', 'o'): 5, ('a', 'e'): 5, ('u', 'u', 'á', 'i'): 5, ('é', 'é'): 4, ('i', 'á'): 3, ('i', 'e', 'e'): 3, ('a', 'a', 'o'): 3, ('e', 'i'): 3, ('e', 'é'): 3, ('á',): 3, ('o', 'a'): 3, ('u', 'a'): 3, ('í', 'e'): 3, ('ü', 'ö', 'ö', 'e'): 3, ('é', 'e'): 3, ('e', 'e', 'e', 'ő'): 2, ('á', 'a'): 2, ('o', 'o', 'ú'): 2, ('o', 'á', 'a'): 2, ('o', 'o', 'o'): 2, ('e', 'ő', 'e'): 2, ('ü', 'ö'): 2, ('o', 'ó'): 2, ('í',): 2, ('a', 'á'): 2, ('e', 'á'): 2, ('ö', 'e', 'e'): 2, ('u', 'o'): 2, ('ú',): 2, ('o', 'á', 'a', 'o'): 2, ('o', 'á', 'o'): 2, ('a', 'e', 'e'): 2, ('é', 'á', 'u'): 2, ('i', 'é'): 2, ('ö', 'é'): 2, ('e', 'e', 'e'): 2, ('a', 'o', 'á', 'o'): 2, ('á', 'i'): 2, ('o', 'i', 'i', 'a', 'i'): 2, ('e', 'é', 'e', 'i'): 2, ('e', 'i', 'á'): 2, ('e', 'e', 'e', 'i'): 2, ('e', 'u', 'ó', 'a', 'i'): 2, ('ó', 'u'): 1, ('ó',): 1, ('o', 'o', 'á', 'á', 'a'): 1, ('o', 'o', 'a'): 1, ('i', 'á', 'a'): 1, ('ó', 'i', 'a'): 1, ('u', 'a', 'o', 'a'): 1, ('ü', 'ö', 'e'): 1, ('o', 'a', 'i', 'á', 'a'): 1, ('e', 'o', 'a'): 1, ('ö', 'ő', 'é', 'e', 'i', 'e'): 1, ('i', 'u', 'i', 'a'): 1, ('a', 'á', 'á', 'é'): 1, ('ú', 'á', 'i', 'a'): 1, ('e', 'i', 'i', 'e', 'e', 'e', 'e'): 1, ('a', 'á', 'u', 'a'): 1, ('e', 'e', 'ő'): 1, ('o', 'a', 'á', 'á', 'a'): 1, ('é', 'e', 'é', 'e'): 1, ('u', 'ó', 'í', 'i', 'a'): 1, ('i', 'é', 'e', 'e'): 1, ('u', 'í', 'i', 'a'): 1, ('o', 'a', 'a'): 1, ('á', 'á'): 1, ('ö', 'i'): 1, ('o', 'a', 'ó'): 1, ('e', 'i', 'e'): 1, ('e', 'e', 'e', 'e'): 1, ('ü', 'e', 'e'): 1, ('o', 'a', 'á', 'a'): 1, ('i', 'e', 'e', 'e'): 1, ('a', 'o', 'a'): 1, ('e', 'i', 'ő'): 1, ('á', 'e'): 1, ('e', 'e', 'í', 'e'): 1, ('i', 'a'): 1, ('a', 'a', 'o', 'i', 'a'): 1, ('i', 'á', 'a', 'i'): 1, ('a', 'o', 'á'): 1, ('ü', 'e', 'é'): 1, ('o', 'i', 'a'): 1, ('ö', 'é', 'e', 'e'): 1, ('ö', 'ö', 'é', 'e'): 1, ('i', 'á', 'e', 'e'): 1, ('ő', 'á', 'o', 'a'): 1, ('e', 'ü'): 1, ('ö', 'ö', 'ű'): 1, ('ü', 'ő', 'i', 'ő'): 1, ('é', 'a', 'a', 'i'): 1, ('i', 'u', 'o'): 1, ('e', 'a', 'á', 'o'): 1, ('e', 'e', 'ő', 'e'): 1, ('ö', 'e', 'ő'): 1, ('e', 'í', 'ü'): 1, ('a', 'á', 'ó'): 1, ('i', 'i', 'ó'): 1, ('a', 'a', 'á', 'a'): 1, ('i', 'a', 'i', 'u', 'a'): 1, ('i', 'o', 'a', 'i', 'a'): 1, ('u', 'i', 'u'): 1, ('o', 'a', 'i', 'ó'): 1, ('o', 'a', 'i'): 1, ('a', 'i', 'a'): 1, ('i', 'á', 'o'): 1, ('í', 'e', 'e'): 1, ('e', 'i', 'e', 'e'): 1, ('a', 'o', 'i'): 1, ('a', 'á', 'é'): 1, ('ö', 'ö'): 1, ('a', 'ú'): 1, ('í', 'i', 'a', 'á', 'a'): 1, ('á', 'é', 'o', 'o'): 1, ('o', 'o', 'ó'): 1, ('i', 'e', 'e', 'e', 'ő', 'e'): 1, ('e', 'ö'): 1, ('é', 'é', 'e', 'i'): 1, ('e', 'a', 'o'): 1, ('é', 'e', 'ű'): 1, ('u', 'i', 'á'): 1, ('i', 'o', 'á', 'a', 'a'): 1, ('é', 'e', 'e', 'i'): 1, ('o', 'o', 'á', 'i'): 1, ('e', 'e', 'i'): 1, ('ü', 'ö', 'e', 'e'): 1, ('i', 'á', 'á'): 1, ('u', 'a', 'a'): 1, ('á', 'o', 'u', 'ú', 'á', 'a'): 1, ('é', 'á'): 1, ('e', 'e', 'i', 'u'): 1, ('e', 'e', 'e', 'e', 'e', 'e'): 1, ('é', 'á', 'o'): 1, ('a', 'ó'): 1, ('é', 'a'): 1, ('i', 'á', 'í', 'ű'): 1, ('ű', 'e', 'e'): 1, ('á', 'u', 'a'): 1, ('a', 'i', 'u'): 1, ('e', 'é', 'e', 'e', 'ő'): 1, ('a', 'i'): 1, ('ü', 'é'): 1, ('ö', 'é', 'e', 'ü', 'e'): 1, ('e', 'e', 'é'): 1, ('u', 'a', 'e', 'i'): 1, ('a', 'a', 'i'): 1, ('u', 'i', 'ó'): 1, ('a', 'o', 'a', 'o'): 1, ('a', 'a', 'á', 'i'): 1, ('e', 'ő', 'é'): 1, ('é', 'o', 'á'): 1, ('ö', 'e', 'é', 'é', 'e'): 1, ('a', 'á', 'a', 'o'): 1, ('a', 'o', 'á', 'o', 'a'): 1, ('e', 'i', 'e', 'i'): 1, ('í', 'e', 'i'): 1})\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:37:41.834017Z",
     "start_time": "2025-02-25T10:37:41.831163Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c686660803906574",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f89c703536479a5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
